{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection signature : Train & Evaluation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“„ **DÃ©tection de Signatures - EntraÃ®nement et Ã‰valuation**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ **Objectif du projet**  \n",
    "L'objectif initial est de pouvoir **automatiser la reconnaissance de documents signÃ©s ou non signÃ©s**.  \n",
    "Cela permettrait :  \n",
    "âœ… D'accÃ©lÃ©rer le traitement automatique des documents.  \n",
    "âœ… D'amÃ©liorer la prÃ©cision de la dÃ©tection de signatures.  \n",
    "âœ… De faciliter la vÃ©rification d'authenticitÃ© des documents.  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” **Contexte du projet**  \n",
    "Les signatures manuscrites ne sont **pas des classes** dÃ©jÃ  prÃ©sentes dans les jeux de donnÃ©es utilisÃ©s pour l'entraÃ®nement initial des modÃ¨les de dÃ©tection d'objets.  \n",
    "Ainsi, une phase de **fine-tuning** est nÃ©cessaire pour ajuster les modÃ¨les :  \n",
    "âœ”ï¸ Tirer parti des poids dÃ©jÃ  prÃ©-entraÃ®nÃ©s sur des bases d'images gÃ©nÃ©rales.  \n",
    "âœ”ï¸ Affiner le modÃ¨le pour dÃ©tecter spÃ©cifiquement des signatures dans des documents.  \n",
    "âœ”ï¸ AmÃ©liorer la capacitÃ© du modÃ¨le Ã  extraire des caractÃ©ristiques spÃ©cifiques aux signatures.  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ **Pourquoi le Fine-Tuning est NÃ©cessaire ?**  \n",
    "Les modÃ¨les de dÃ©tection d'objets (comme YOLO, Faster R-CNN, RetinaNet, etc.) sont gÃ©nÃ©ralement prÃ©-entraÃ®nÃ©s sur des jeux de donnÃ©es comme **COCO** ou **ImageNet**.  \n",
    "ğŸ‘‰ Cependant, ces jeux de donnÃ©es ne contiennent pas de classes spÃ©cifiques aux signatures manuscrites.  \n",
    "ğŸ‘‰ Un ajustement est donc nÃ©cessaire pour adapter le modÃ¨le Ã  ce cas d'usage particulier.  \n",
    "\n",
    "### â¡ï¸ **Avantages du Fine-Tuning :**  \n",
    "âœ… AccÃ©lÃ©ration du processus d'entraÃ®nement grÃ¢ce aux poids dÃ©jÃ  prÃ©-entraÃ®nÃ©s.  \n",
    "âœ… Extraction de caractÃ©ristiques gÃ©nÃ©rales des images (formes, textures, motifs).  \n",
    "âœ… Adaptation rapide Ã  un domaine spÃ©cifique (reconnaissance de signatures).  \n",
    "âœ… Optimisation plus rapide et plus efficace.  \n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ **Approche Technique**  \n",
    "### 1. **PrÃ©paration des DonnÃ©es :**  \n",
    "- Extraction des signatures depuis des fichiers PDF.  \n",
    "- Annotation manuelle des signatures dans les documents (bounding boxes).  \n",
    "- Augmentation des donnÃ©es pour enrichir le dataset (rotation, recadrage, etc.).  \n",
    "\n",
    "### 2. **ModÃ¨les UtilisÃ©s :**  \n",
    "- ğŸ”¹ **YOLOv8** \n",
    "- ğŸ”¹ **YOLOv11**  \n",
    "\n",
    "\n",
    "### 3. **StratÃ©gie de Fine-Tuning :**  \n",
    "âœ”ï¸ Chargement des poids prÃ©-entraÃ®nÃ©s.  \n",
    "âœ”ï¸ CongÃ©lation des premiÃ¨res couches du modÃ¨le (pour conserver les caractÃ©ristiques gÃ©nÃ©rales).  \n",
    "âœ”ï¸ Ajustement des couches finales pour apprendre la spÃ©cificitÃ© des signatures.  \n",
    "âœ”ï¸ EntraÃ®nement du modÃ¨le avec des hyperparamÃ¨tres adaptÃ©s :  \n",
    "- Taux d'apprentissage (`learning rate`)  \n",
    "- Taille de batch (`batch size`)  \n",
    "- Nombre d'Ã©poques (`epochs`)  \n",
    "âœ”ï¸ Ajustement de la fonction de perte pour une meilleure convergence.  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š **Ã‰valuation des ModÃ¨les**  \n",
    "- **PrÃ©cision (Precision)** â€“ capacitÃ© Ã  ne dÃ©tecter que des signatures rÃ©elles.  \n",
    "- **Rappel (Recall)** â€“ capacitÃ© Ã  dÃ©tecter toutes les signatures prÃ©sentes.  \n",
    "- **mAP (mean Average Precision)** â€“ score moyen global de dÃ©tection.  \n",
    "- **F1-Score** â€“ Ã©quilibre entre la prÃ©cision et le rappel.  \n",
    "- **Taux de faux positifs/nÃ©gatifs** â€“ capacitÃ© Ã  Ã©viter les erreurs de dÃ©tection.  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ† **RÃ©sultats Attendus**  \n",
    "âœ… DÃ©tection fiable des signatures dans diffÃ©rents types de documents.  \n",
    "âœ… RÃ©duction du nombre de faux positifs et faux nÃ©gatifs.  \n",
    "âœ… Optimisation rapide grÃ¢ce Ã  l'utilisation de poids prÃ©-entraÃ®nÃ©s.  \n",
    "âœ… Automatisation du processus de validation de documents signÃ©s.  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš¨ **DÃ©fis Potentiels**  \n",
    "âš ï¸ Mauvaise qualitÃ© des signatures (floues, partielles, surimposÃ©es).  \n",
    "âš ï¸ VariabilitÃ© des styles de signature (taille, forme, orientation).  \n",
    "âš ï¸ PrÃ©sence de bruits visuels (tampons, annotations).  \n",
    "âš ï¸ Ã‰quilibre entre la prÃ©cision et le rappel.  \n",
    "\n",
    "---\n",
    "\n",
    "## âœ… **Prochaines Ã‰tapes**  \n",
    "ğŸ” Ã‰valuer la performance des modÃ¨les aprÃ¨s fine-tuning.  \n",
    "ğŸ“‰ Comparer les rÃ©sultats des diffÃ©rents modÃ¨les.  \n",
    "ğŸ§ª Ajuster les hyperparamÃ¨tres pour amÃ©liorer la convergence.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: supervision in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (0.25.1)\n",
      "Collecting roboflow\n",
      "  Downloading roboflow-1.1.56-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.7 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (1.3.1)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (0.7.1)\n",
      "Requirement already satisfied: matplotlib>=3.6.0 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (1.26.4)\n",
      "Requirement already satisfied: opencv-python>=4.5.5.64 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=9.4 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (2.32.3)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (1.14.1)\n",
      "Requirement already satisfied: tqdm>=4.62.3 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (4.66.5)\n",
      "Requirement already satisfied: certifi in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from roboflow) (2024.12.14)\n",
      "Collecting idna==3.7 (from roboflow)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: cycler in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from roboflow) (1.4.7)\n",
      "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Collecting python-dotenv (from roboflow)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: six in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from roboflow) (1.26.20)\n",
      "Collecting requests-toolbelt (from roboflow)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting filetype (from roboflow)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from matplotlib>=3.6.0->supervision) (4.55.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from matplotlib>=3.6.0->supervision) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from matplotlib>=3.6.0->supervision) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from requests>=2.26.0->supervision) (3.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from tqdm>=4.62.3->supervision) (0.4.6)\n",
      "Downloading roboflow-1.1.56-py3-none-any.whl (83 kB)\n",
      "Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Installing collected packages: filetype, python-dotenv, opencv-python-headless, idna, requests-toolbelt, roboflow\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\ilyes\\intelligIA\\myenv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\ilyes\\intelligIA\\myenv\\Lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] AccÃ¨s refusÃ©: 'c:\\\\Users\\\\ilyes\\\\intelligIA\\\\myenv\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade supervision roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "import math\n",
    "import yaml\n",
    "from typing import Optional\n",
    "import requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import gc\n",
    "import numpy as np\n",
    "from random import randrange, sample\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import dataclasses\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, List, Type, Union, Callable\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import uuid\n",
    "\n",
    "from IPython.display import Markdown, display, Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import supervision as sv\n",
    "import glob\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(\"logger\")\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“‚ **Dataset**\n",
    "\n",
    "---\n",
    "\n",
    "## **PrÃ©sentation du Dataset**  \n",
    "Ce dataset a Ã©tÃ© dÃ©veloppÃ© pour entraÃ®ner des modÃ¨les de dÃ©tection de signatures manuscrites dans divers types de documents.  \n",
    "Il combine des donnÃ©es provenant de plusieurs sources publiques et d'un dataset personnalisÃ© dÃ©veloppÃ© par **IntelligIA**.  \n",
    "Les donnÃ©es ont Ã©tÃ© soigneusement annotÃ©es et unifiÃ©es dans un format standardisÃ© **COCO JSON** pour une compatibilitÃ© optimale avec les modÃ¨les de dÃ©tection d'objets.  \n",
    "\n",
    "---\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td style=\"text-align: center; padding: 10px;\">\n",
    "      <a href=\"https://universe.roboflow.com/tech-ysdkk/signature-detection-hlx8j\">\n",
    "        <img src=\"https://app.roboflow.com/images/download-dataset-badge.svg\">\n",
    "      </a>\n",
    "    </td>\n",
    "    <td style=\"text-align: center; padding: 10px;\">\n",
    "      <a href=\"https://huggingface.co/datasets/tech4humans/signature-detection\">\n",
    "        <img src=\"https://huggingface.co/datasets/huggingface/badges/resolve/main/dataset-on-hf-md.svg\" alt=\"Dataset on HF\">\n",
    "      </a>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "---\n",
    "\n",
    "## **Composantes du Dataset**  \n",
    "### ğŸ”¹ **1. Tobacco800** ([Lien](https://paperswithcode.com/dataset/tobacco-800))  \n",
    "- Un sous-ensemble du **Complex Document Image Processing (CDIP)** Test Collection.  \n",
    "- Contient des images scannÃ©es de documents liÃ©s Ã  l'industrie du tabac.  \n",
    "- CrÃ©Ã© par l'Institut de Technologie de l'Illinois (IIT).  \n",
    "- **Format :** TIFF converti en COCO JSON.  \n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ **2. Signatures-XC8UP** ([Lien](https://universe.roboflow.com/roboflow-100/signatures-xc8up))  \n",
    "- Fait partie de **Roboflow 100**, une initiative d'Intel.  \n",
    "- Contient **368 images annotÃ©es** pour la dÃ©tection de signatures manuscrites.  \n",
    "- Les annotations sont en format **COCO JSON**.  \n",
    "- **Types de signatures :** VariÃ©tÃ© de styles et de tailles.  \n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ **3. Dataset IntelligIA**  \n",
    "- CrÃ©Ã© et annotÃ© manuellement par **IntelligIA** pour une tÃ¢che spÃ©cifique de dÃ©tection de signatures dans des documents professionnels.  \n",
    "- Inclut **178 images** de documents (format PDF, JPEG et PNG).  \n",
    "- Les annotations sont en **format COCO JSON**.  \n",
    "- Les donnÃ©es sont issues de documents rÃ©els (assurances, contrats, formulaires).  \n",
    "- **Types de signatures dÃ©tectÃ©es :**  \n",
    "    - Signatures manuscrites.  \n",
    "    - Signatures Ã©lectroniques.  \n",
    "    - Signatures partiellement visibles ou incomplÃ¨tes.  \n",
    "\n",
    "---\n",
    "\n",
    "## **DÃ©tails du Dataset**  \n",
    "| Type de DonnÃ©es | Nombre d'Images | % du Total |\n",
    "|-----------------|------------------|------------|\n",
    "| **EntraÃ®nement** | 1 980 | 70% |\n",
    "| **Validation**   | 420   | 15% |\n",
    "| **Test**         | 419   | 15% |\n",
    "| **Total**        | 2 819 | 100% |\n",
    "\n",
    "---\n",
    "\n",
    "## **Format du Dataset**  \n",
    "âœ… **Format :** COCO JSON  \n",
    "âœ… **Taille des fichiers :** 1.2 Go  \n",
    "âœ… **Licence :** Apache 2.0  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š **Pourquoi ces Datasets ?**  \n",
    "âœ… Le dataset **Tobacco800** permet une meilleure reconnaissance de texte complexe dans des documents professionnels.  \n",
    "âœ… Le dataset **Signatures-XC8UP** amÃ©liore la reconnaissance de signatures manuscrites.  \n",
    "âœ… Le dataset **IntelligIA** permet une adaptation Ã  des documents rÃ©els professionnels (assurances, contrats).  \n",
    "âœ… La diversitÃ© des donnÃ©es permet au modÃ¨le d'apprendre Ã  dÃ©tecter des signatures dans diffÃ©rents contextes, styles et qualitÃ©s d'image.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Datasets yolo format to coco json format :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Conversion YOLO â†’ COCO en cours...\n",
      "ğŸ” Traitement de l'image : 01 Arrâ•¦Ã¥tÃ”Ã‡Ãœ de permis de construire_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : 01 Arrâ•¦Ã¥tÃ”Ã‡Ãœ permis de construire_BESSAN_page-0002.jpg\n",
      "ğŸ” Traitement de l'image : 01 Arrâ•¦Ã¥tÃ”Ã‡Ãœ permis de construire_BESSAN_page-0005.jpg\n",
      "ğŸ” Traitement de l'image : 01 Arrâ•¦Ã¥tÃ”Ã‡Ãœ permis de construire_BESSAN_page-0009.jpg\n",
      "ğŸ” Traitement de l'image : 01 Arrâ•¦Ã¥tÃ”Ã‡Ãœ permis de construire_BESSAN_page-0011.jpg\n",
      "ğŸ” Traitement de l'image : 01 Arrâ•¦Ã¥tÃ”Ã‡Ãœ permis de construire_BESSAN_page-0015.jpg\n",
      "ğŸ” Traitement de l'image : 01 Arrâ•¦Ã¥tÃ”Ã‡Ãœ permis de construire_BESSAN_page-0017.jpg\n",
      "ğŸ” Traitement de l'image : 01 Arrâ•¦Ã¥tÃ”Ã‡Ãœ permis de construire_BESSAN_page-0025.jpg\n",
      "ğŸ” Traitement de l'image : 01. Arrâ•¦Ã¥tÃ”Ã‡Ãœ de permis de construire Arles_page-0003.jpg\n",
      "ğŸ” Traitement de l'image : 01. Arrâ•¦Ã¥tÃ”Ã‡Ãœ de permis de construire Arles_page-0008.jpg\n",
      "ğŸ” Traitement de l'image : 01. Arrâ•¦Ã¥tÃ”Ã‡Ãœ de permis de construire Arles_page-0011.jpg\n",
      "ğŸ” Traitement de l'image : 01. Arrâ•¦Ã¥tÃ”Ã‡Ãœ de permis de construire Arles_page-0015.jpg\n",
      "ğŸ” Traitement de l'image : 01. Arrâ•¦Ã¥tÃ”Ã‡Ãœ de permis de construire Arles_page-0016.jpg\n",
      "ğŸ” Traitement de l'image : 01. Arrâ•¦Ã¥tÃ”Ã‡Ãœ de permis de construire Arles_page-0017.jpg\n",
      "ğŸ” Traitement de l'image : 01. Arrâ•¦Ã¥tÃ”Ã‡Ãœ de permis de construireB0134-Bayonne_pages-to-jpg-0002.jpg\n",
      "ğŸ” Traitement de l'image : 01. Arrâ•¦Ã¥tÃ”Ã‡Ãœ de permis de construire_ARLES BAYONNE_page-0002.jpg\n",
      "ğŸ” Traitement de l'image : 03. Attestation de non recours - TA Arles_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : 04 Cerfa signÃ”Ã‡Ãœ - PC Vendargue 2-M0054_page-0008.jpg\n",
      "ğŸ” Traitement de l'image : 04 Cerfa signÃ”Ã‡Ãœ - PC Vendargue 2-M0054_page-0018.jpg\n",
      "ğŸ” Traitement de l'image : 2020 05 15 - arrâ•¦Ã¥tÃ”Ã‡Ãœ dÃ”Ã‡Ãœclaration prÃ”Ã‡Ãœalable travaux CrÃ”Ã‡Ãœteil DP 94028 20 C4023_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : 2020 05 15 - arrâ•¦Ã¥tÃ”Ã‡Ãœ dÃ”Ã‡Ãœclaration prÃ”Ã‡Ãœalable travaux CrÃ”Ã‡Ãœteil DP 94028 20 C4023_page-0003.jpg\n",
      "ğŸ” Traitement de l'image : 2020 05 15 - arrâ•¦Ã¥tÃ”Ã‡Ãœ dÃ”Ã‡Ãœclaration prÃ”Ã‡Ãœalable travaux CrÃ”Ã‡Ãœteil DP 94028 20 C4023_page-0004.jpg\n",
      "ğŸ” Traitement de l'image : 2020 05 15 - arrâ•¦Ã¥tÃ”Ã‡Ãœ dÃ”Ã‡Ãœclaration prÃ”Ã‡Ãœalable travaux CrÃ”Ã‡Ãœteil DP 94028 20 C4023_page-0005.jpg\n",
      "ğŸ” Traitement de l'image : 2020 05 15 - arrâ•¦Ã¥tÃ”Ã‡Ãœ dÃ”Ã‡Ãœclaration prÃ”Ã‡Ãœalable travaux CrÃ”Ã‡Ãœteil DP 94028 20 C4023_page-0012.jpg\n",
      "ğŸ” Traitement de l'image : 2020 05 15 - arrâ•¦Ã¥tÃ”Ã‡Ãœ dÃ”Ã‡Ãœclaration prÃ”Ã‡Ãœalable travaux CrÃ”Ã‡Ãœteil DP 94028 20 C4023_page-0019.jpg\n",
      "ğŸ” Traitement de l'image : 2020 06 18 - 1er PV de constat d'affichage_page-0005.jpg\n",
      "ğŸ” Traitement de l'image : 2020 07 20 - 2Ã¾Ã³â•‘e PV de constat d'affichage_page-0006.jpg\n",
      "ğŸ” Traitement de l'image : 2020 08 18 - 3Ã¾Ã³â•‘e PV de constat d'affichage_page-0006.jpg\n",
      "ğŸ” Traitement de l'image : AFFICHAGE 1ER PASSAGE_MARSEILLE_page-0005.jpg\n",
      "ğŸ” Traitement de l'image : Atterstation non recours des tiers BOE_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : Attestation Conformite PC18Y0009 Aubergenville_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : Attestation conformitÃ”Ã‡Ãœ LOON PLAGE_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : Attestation conformitÃ”Ã‡Ãœ LOON PLAGE_page-0002.jpg\n",
      "ğŸ” Traitement de l'image : Attestation de non recours au PC (TA)_BOE_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : Attestation de non recours TA - Loom-Plage_DUNKERQUE_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : Attestation de non recours TA-1_Beziers_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : Attestation de non recours TA-9Baziege_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : Attestation non contestation PC 1 Bayonne_27 06 2022_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : Attestation non contestation PC 2 Bayonne_27 06 2022_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : Attestation non recours TA - Marseille 2_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : AUBERGENVILLE - DAACT - 2021_page-0002.jpg\n",
      "ğŸ” Traitement de l'image : AUBERGENVILLE - DAACT - 2021_page-0004.jpg\n",
      "ğŸ” Traitement de l'image : Avenant contrat HEL 2025 - SignÃ©_page-0002.jpg\n",
      "ğŸ” Traitement de l'image : BESSAN - Certificat de non opposition conformitÃ”Ã‡Ãœ des travaux 17-11-2022_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : BESSAN 1 - RÃ”Ã‡ÃœcÃ”Ã‡ÃœpissÃ”Ã‡Ãœ DAACT - PC 34031 19 K0016 - 01.06.22_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : BESSAN 1 - RÃ”Ã‡ÃœcÃ”Ã‡ÃœpissÃ”Ã‡Ãœ DAACT - PC 34031 19 K0016 - 01.06.22_page-0002.jpg\n",
      "ğŸ” Traitement de l'image : BESSAN-Certificat de non opposition conformitÃ”Ã‡Ãœ des travaux 17-11-2022_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : Cartificat de conformitÃ”Ã‡Ãœ 25.01.2010_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : certificat conformitÃ”Ã‡Ãœ immeuble voisin 2013_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : DAACT - BAYONNE 2 - Cerfa - Avis de rÃ”Ã‡Ãœception 12.01.22_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : DAACT immeuble voisin 2012_page-0002.jpg\n",
      "ğŸ” Traitement de l'image : DAT 10 avril 1985_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : DOC bessan PC 2_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : DOC bessan PC 2_page-0003.jpg\n",
      "ğŸ” Traitement de l'image : DROC 1er novembre 1984_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : DROC 3 juin 1985_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : dÃ”Ã‡Ãœclaration achSâ• Ã®vement travaux 13 septembre 1985_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : DÃ”Ã‡Ãœclaration achSâ• Ã®vement travaux 3 juin 1985_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : DÃ”Ã‡Ãœclaration d'ouverture de chantier du 20.03.1975_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : Permis de construire_CASTELNAU bis_page-0002.jpg\n",
      "ğŸ” Traitement de l'image : Permis de construire_CASTELNAU_page-0002.jpg\n",
      "ğŸ” Traitement de l'image : Permis de construire_CASTELNAU_page-0004.jpg\n",
      "ğŸ” Traitement de l'image : Permis de construire_CLERMONT_pages-to-jpg-0001.jpg\n",
      "ğŸ” Traitement de l'image : Permis de construire_CLERMONT_pages-to-jpg-0003.jpg\n",
      "ğŸ” Traitement de l'image : Permis de construire_DUNKERQUE_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : Permis de construire_DUNKERQUE_page-0002.jpg\n",
      "ğŸ” Traitement de l'image : Permis de construire_DUNKERQUE_page-0003.jpg\n",
      "ğŸ” Traitement de l'image : Permis de construire_LONGVIC_page-0003.jpg\n",
      "ğŸ” Traitement de l'image : Permis de construire_LONGVIC_page-0005.jpg\n",
      "ğŸ” Traitement de l'image : Permis de construire_LONGVIC_page-0008.jpg\n",
      "ğŸ” Traitement de l'image : Permis de construire_LONGVIC_page-0010.jpg\n",
      "ğŸ” Traitement de l'image : Permis de construire_LONGVIC_page-0011.jpg\n",
      "ğŸ” Traitement de l'image : Resotainer_Beziers DROC valide_page-0001.jpg\n",
      "ğŸ” Traitement de l'image : Resotainer_Beziers DROC valide_page-0002.jpg\n",
      "ğŸ” Traitement de l'image : Screenshot-2024-07-30-094419_png.rf.2d363b9b0ee22beccd670b736beeccaa.jpg\n",
      "ğŸ” Traitement de l'image : signed_agreement_1.jpg\n",
      "ğŸ” Traitement de l'image : yrz52d00_png.rf.a77b190c8f35247852ca7313ca12b92d.jpg\n",
      "ğŸ” Traitement de l'image : 10_page_77.png\n",
      "ğŸ” Traitement de l'image : 15_page_1.png\n",
      "ğŸ” Traitement de l'image : 15_page_16.png\n",
      "ğŸ” Traitement de l'image : 16_page_1.png\n",
      "ğŸ” Traitement de l'image : 17_page_1.png\n",
      "ğŸ” Traitement de l'image : 17_page_16.png\n",
      "ğŸ” Traitement de l'image : 18_page_2.png\n",
      "ğŸ” Traitement de l'image : 19_page_1.png\n",
      "ğŸ” Traitement de l'image : 1_page_1.png\n",
      "ğŸ” Traitement de l'image : 1_page_75.png\n",
      "ğŸ” Traitement de l'image : 2023 Attestation BAYONNE_page_1.png\n",
      "ğŸ” Traitement de l'image : 2023 Attestation BÃ•Ã‡Ã¥iers_page_1.png\n",
      "ğŸ” Traitement de l'image : 2023 Attestation Marseille_page_1.png\n",
      "ğŸ” Traitement de l'image : 22_page_1.png\n",
      "ğŸ” Traitement de l'image : 24_page_11.png\n",
      "ğŸ” Traitement de l'image : 25_page_1.png\n",
      "ğŸ” Traitement de l'image : 26_page_1.png\n",
      "ğŸ” Traitement de l'image : 27_page_1.png\n",
      "ğŸ” Traitement de l'image : 29_page_1.png\n",
      "ğŸ” Traitement de l'image : 2_page_1.png\n",
      "ğŸ” Traitement de l'image : 30_page_1.png\n",
      "ğŸ” Traitement de l'image : 32_page_1.png\n",
      "ğŸ” Traitement de l'image : 33_page_1.png\n",
      "ğŸ” Traitement de l'image : 35_page_1.png\n",
      "ğŸ” Traitement de l'image : 36_page_1.png\n",
      "ğŸ” Traitement de l'image : 38_page_1.png\n",
      "ğŸ” Traitement de l'image : 39_page_1.png\n",
      "ğŸ” Traitement de l'image : 40_page_1.png\n",
      "ğŸ” Traitement de l'image : 41_page_1.png\n",
      "ğŸ” Traitement de l'image : 42_page_1.png\n",
      "ğŸ” Traitement de l'image : 43_page_1.png\n",
      "ğŸ” Traitement de l'image : 45_page_1.png\n",
      "ğŸ” Traitement de l'image : 46_page_1.png\n",
      "ğŸ” Traitement de l'image : 47_page_1.png\n",
      "ğŸ” Traitement de l'image : 48_page_1.png\n",
      "ğŸ” Traitement de l'image : 4_page_9.png\n",
      "ğŸ” Traitement de l'image : 50_page_1.png\n",
      "ğŸ” Traitement de l'image : 51_page_1.png\n",
      "ğŸ” Traitement de l'image : 52_page_1.png\n",
      "ğŸ” Traitement de l'image : 53_page_1.png\n",
      "ğŸ” Traitement de l'image : 55_page_1.png\n",
      "ğŸ” Traitement de l'image : 56_page_1.png\n",
      "ğŸ” Traitement de l'image : 57_page_1.png\n",
      "ğŸ” Traitement de l'image : 59_page_1.png\n",
      "ğŸ” Traitement de l'image : 5_page_1.png\n",
      "ğŸ” Traitement de l'image : 5_page_5.png\n",
      "ğŸ” Traitement de l'image : 61_page_1.png\n",
      "ğŸ” Traitement de l'image : 62_page_1.png\n",
      "ğŸ” Traitement de l'image : 63_page_1.png\n",
      "ğŸ” Traitement de l'image : 64_page_1.png\n",
      "ğŸ” Traitement de l'image : 66_page_1.png\n",
      "ğŸ” Traitement de l'image : 67_page_1.png\n",
      "ğŸ” Traitement de l'image : 69_page_1.png\n",
      "ğŸ” Traitement de l'image : 70_page_1.png\n",
      "ğŸ” Traitement de l'image : 72_page_1.png\n",
      "ğŸ” Traitement de l'image : 73_page_1.png\n",
      "ğŸ” Traitement de l'image : 7_page_16.png\n",
      "ğŸ” Traitement de l'image : 8_page_1.png\n",
      "ğŸ” Traitement de l'image : 9_page_1.png\n",
      "ğŸ” Traitement de l'image : 9_page_3.png\n",
      "ğŸ” Traitement de l'image : AREAS - RESOTAINER - Avenant 2021_page_3.png\n",
      "ğŸ” Traitement de l'image : AREAS - RESOTAINER - Avenant 2021_page_5.png\n",
      "ğŸ” Traitement de l'image : AREAS - RESOTAINER BESSAN - Attestation d_Assurance 2021_page_1.png\n",
      "ğŸ” Traitement de l'image : AREAS - RESOTAINER BOE - Attestation d'Assurance 2021_BOE_page_1.png\n",
      "ğŸ” Traitement de l'image : AREAS - RESOTAINER BOE - Attestation d_Assurance 2021_page_1.png\n",
      "ğŸ” Traitement de l'image : AREAS - RESOTAINER BOIS GRENIER - Attestation d'Assurance 2021_page_1.png\n",
      "ğŸ” Traitement de l'image : AREAS - RESOTAINER BOIS GRENIER - Attestation d_Assurance 2021_page_1.png\n",
      "ğŸ” Traitement de l'image : ARNAL - Attestation d'Assurance - RC 2021_page_3.png\n",
      "ğŸ” Traitement de l'image : Assurances AREAS - RESOTAINER BESSAN - Attestation d'Assurance 2021_page_1.png\n",
      "ğŸ” Traitement de l'image : Attestation Areas Site Bessan 2_page_1.png\n",
      "ğŸ” Traitement de l'image : attestation assurance multirisque immeuble  6 mai 2019 29 Casanova_page_1.png\n",
      "ğŸ” Traitement de l'image : attestation assurance multirisque immeuble 17 octobre 2019 Casanova_page_1.png\n",
      "ğŸ” Traitement de l'image : Attestation assurance multirisque professionnelle 17 octobre 2019 Casanova_page_1.png\n",
      "ğŸ” Traitement de l'image : attestation assurance RC 27.12.2019_page_1.png\n",
      "ğŸ” Traitement de l'image : attestation de FIP charges a jour_page_1.png\n",
      "ğŸ” Traitement de l'image : Attestation immeuble 2024.signed_page_1.png\n",
      "ğŸ” Traitement de l'image : Attestation immeuble SARL HADAR 2025_page_1.png\n",
      "ğŸ” Traitement de l'image : Attestation MRP contrat nâ”œÂ©10612066704.signed_page_1.png\n",
      "ğŸ” Traitement de l'image : Attestation MRP contrat nâ”œÂ©1693112904.signed_page_1.png\n",
      "ğŸ” Traitement de l'image : Attestation non sinistralitÃ”Ã‡Ãœ SARL HADAR MRP contrat nâ”œÂ©10612066704_page_1.png\n",
      "ğŸ” Traitement de l'image : Attestation non sinistralitÃ”Ã‡Ãœ SARL HADAR MRP_page_1.png\n",
      "ğŸ” Traitement de l'image : attestation_page_1.png\n",
      "ğŸ” Traitement de l'image : CASANOVA - Attestation multirisque_page_1.png\n",
      "ğŸ” Traitement de l'image : CLERMONT L HERAULT 2024_page_1.png\n",
      "ğŸ” Traitement de l'image : Conditions particulieres  multirisque professionnelle  Casanova fevrier 2012_page_12.png\n",
      "ğŸ” Traitement de l'image : Contrat assurance multirisque - AXA copropriÃ”Ã‡ÃœtÃ”Ã‡Ãœ (29 Danielle casanova 75001 Paris (002)_page_5.png\n",
      "ğŸ” Traitement de l'image : CP signÃ”Ã‡Ãœ MRP -HADAR contrat fait en 2019_page_9.png\n",
      "ğŸ” Traitement de l'image : FIN TRAVAUX MARSEILLE PC01_page_2.png\n",
      "ğŸ” Traitement de l'image : FIN TRAVAUX MARSEILLE PC02_page_2.png\n",
      "ğŸ” Traitement de l'image : GAN - RESOTAINER BAYONNE - Attestation d'assurance 2022 prime payÃ”Ã‡Ãœe_page_1.png\n",
      "ğŸ” Traitement de l'image : GAN - RESOTAINER TOULOUSE - Attestation d'assurance 2022 prime payÃ”Ã‡Ãœe + PE_page_1.png\n",
      "ğŸ” Traitement de l'image : MAJESTIC PASSY  ATTESTATION _11225583804_page_1.png\n",
      "ğŸ” Traitement de l'image : MAJESTIC PASSY NOUVELLES DISPOSITIONS PARTICULIERES FONCIERE PARIS PASSY_page_2.png\n",
      "ğŸ” Traitement de l'image : MAJESTIC PASSY NOUVELLES DISPOSITIONS PARTICULIERES FONCIERE PARIS PASSY_page_9.png\n",
      "ğŸ” Traitement de l'image : MRI Flandre - CP AFM_page_3.png\n",
      "ğŸ” Traitement de l'image : POINT DU JOUR  Dispositions particuliÃ¨res GENERALI du 15 05 2020_page_1.png\n",
      "ğŸ” Traitement de l'image : POINT DU JOUR Attestation d'assurance du 06 10 2022_page_1.png\n",
      "ğŸ” Traitement de l'image : TOSCA II - 2022-07 SHIF - Police CHUBB FRPAKA64274_page_77.png\n",
      "ğŸ” Traitement de l'image : TOSCA II _2023.03.23-Attestation_de_paiement_de_la_prime_(HÃ”TEL_Lâ€™INTERCONTINENTAL)_page_1.png\n",
      "âœ… Fichier COCO JSON sauvegardÃ© : dataset_coco.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import sys\n",
    "import io\n",
    "\n",
    "\n",
    "IMG_DIR = 'datasets/signature/train/images/'    \n",
    "LABEL_DIR = 'datasets/signature/train/labels/'   \n",
    "OUTPUT_JSON = 'dataset_coco.json'\n",
    "\n",
    "\n",
    "CATEGORIES = [\n",
    "    {\"id\": 0, \"name\": \"signature\"}\n",
    "]\n",
    "\n",
    "\n",
    "images = []\n",
    "annotations = []\n",
    "categories = CATEGORIES\n",
    "annotation_id = 1\n",
    "\n",
    "\n",
    "def sanitize_path(path):\n",
    "    return os.path.normpath(path)\n",
    "\n",
    "\n",
    "def read_image(img_path):\n",
    "    try:\n",
    "\n",
    "        img_path_encoded = os.fsencode(img_path).decode('utf-8')\n",
    "        image = cv2.imdecode(np.fromfile(img_path_encoded, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erreur lors de la lecture de l'image {img_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def yolo_to_coco():\n",
    "    global annotation_id\n",
    "\n",
    "  \n",
    "    image_paths = glob.glob(sanitize_path(os.path.join(IMG_DIR, '*.jpg'))) + \\\n",
    "                  glob.glob(sanitize_path(os.path.join(IMG_DIR, '*.png')))\n",
    "\n",
    "    image_id = 1\n",
    "    for img_path in image_paths:\n",
    "        try:\n",
    "            file_name = os.path.basename(img_path)\n",
    "            print(f\"ğŸ” Traitement de l'image : {file_name}\")\n",
    "\n",
    "    \n",
    "            image = read_image(img_path)\n",
    "            if image is None:\n",
    "                print(f\"âŒ Impossible de lire l'image : {img_path}\")\n",
    "                continue\n",
    "\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            images.append({\n",
    "                'id': image_id,\n",
    "                'file_name': file_name,\n",
    "                'height': height,\n",
    "                'width': width\n",
    "            })\n",
    "\n",
    "            label_path_jpg = sanitize_path(os.path.join(LABEL_DIR, file_name.replace('.jpg', '.txt')))\n",
    "            label_path_png = sanitize_path(os.path.join(LABEL_DIR, file_name.replace('.png', '.txt')))\n",
    "            label_path = label_path_jpg if os.path.exists(label_path_jpg) else label_path_png\n",
    "\n",
    "            if os.path.exists(label_path):\n",
    "                with open(label_path, 'r', encoding='utf-8') as f:\n",
    "                    lines = f.readlines()\n",
    "                    for line in lines:\n",
    "                        try:\n",
    "                            class_id, x_center, y_center, w, h = map(float, line.strip().split())\n",
    "\n",
    "                            x = int((x_center - w / 2) * width)\n",
    "                            y = int((y_center - h / 2) * height)\n",
    "                            w = int(w * width)\n",
    "                            h = int(h * height)\n",
    "\n",
    "                            annotations.append({\n",
    "                                'id': annotation_id,\n",
    "                                'image_id': image_id,\n",
    "                                'category_id': int(class_id),\n",
    "                                'bbox': [x, y, w, h],\n",
    "                                'area': w * h,\n",
    "                                'iscrowd': 0\n",
    "                            })\n",
    "\n",
    "                            annotation_id += 1\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(f\"âŒ Erreur lors du traitement de l'annotation : {line.strip()} â†’ {e}\")\n",
    "\n",
    "            else:\n",
    "                print(f\"âš ï¸ Aucun fichier d'annotation trouvÃ© pour l'image : {file_name}\")\n",
    "\n",
    "            image_id += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erreur lors du traitement de l'image {file_name} : {e}\")\n",
    "\n",
    "\n",
    "print(\"ğŸ”„ Conversion YOLO â†’ COCO en cours...\")\n",
    "yolo_to_coco()\n",
    "\n",
    "coco_output = {\n",
    "    'images': images,\n",
    "    'annotations': annotations,\n",
    "    'categories': categories\n",
    "}\n",
    "\n",
    "with open(OUTPUT_JSON, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(coco_output, json_file, indent=4)\n",
    "\n",
    "print(f\"âœ… Fichier COCO JSON sauvegardÃ© : {OUTPUT_JSON}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display dataset sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Chargement des images avec annotations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 36 images chargÃ©es et annotÃ©es.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1500 with 36 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "IMG_DIR = 'datasets/signature/train/images'\n",
    "LABEL_DIR = 'datasets/signature/train/labels'\n",
    "GRID_SIZE = 6\n",
    "\n",
    "CLASSES = [\"signature\"]\n",
    "\n",
    "def load_yolo_annotations(label_path, width, height):\n",
    "    annotations = []\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r', encoding='utf-8') as f:  \n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                try:\n",
    "                    class_id, x_center, y_center, w, h = map(float, line.strip().split())\n",
    "                    x = int((x_center - w / 2) * width)\n",
    "                    y = int((y_center - h / 2) * height)\n",
    "                    w = int(w * width)\n",
    "                    h = int(h * height)\n",
    "                    annotations.append({\n",
    "                        'class_id': int(class_id),\n",
    "                        'bbox': [x, y, w, h]\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ Erreur lors de la lecture de l'annotation : {e}\")\n",
    "    return annotations\n",
    "\n",
    "def annotate_image(image, annotations):\n",
    "    for ann in annotations:\n",
    "        x, y, w, h = ann['bbox']\n",
    "        class_id = ann['class_id']\n",
    "        label = CLASSES[class_id]\n",
    "        \n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(\n",
    "            image, \n",
    "            label, \n",
    "            (x, y - 10), \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "            0.6, \n",
    "            (0, 255, 0), \n",
    "            2\n",
    "        )\n",
    "    return image\n",
    "\n",
    "def load_and_annotate_images():\n",
    "    images = []\n",
    "    \n",
    "    image_paths = glob.glob(os.path.join(IMG_DIR, '*.jpg')) + glob.glob(os.path.join(IMG_DIR, '*.png'))\n",
    "    \n",
    "    image_paths = [path.replace(\"\\\\\", \"/\") for path in image_paths]\n",
    "    \n",
    "    for img_path in image_paths[:GRID_SIZE * GRID_SIZE]:\n",
    "        try:\n",
    "            file_name = os.path.basename(img_path)\n",
    "            label_path_jpg = os.path.join(LABEL_DIR, file_name.replace('.jpg', '.txt'))\n",
    "            label_path_png = os.path.join(LABEL_DIR, file_name.replace('.png', '.txt'))\n",
    "            label_path = label_path_jpg if os.path.exists(label_path_jpg) else label_path_png\n",
    "\n",
    "            if not os.path.exists(img_path):\n",
    "                print(f\"âŒ Fichier introuvable : {img_path}\")\n",
    "                continue\n",
    "\n",
    "           \n",
    "            image = cv2.imdecode(np.fromfile(img_path, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "            if image is None:\n",
    "                print(f\"âŒ Erreur lors du chargement de l'image : {img_path}\")\n",
    "                continue\n",
    "\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "           \n",
    "            annotations = load_yolo_annotations(label_path, width, height)\n",
    "\n",
    "           \n",
    "            annotated_image = annotate_image(image.copy(), annotations)\n",
    "\n",
    "    \n",
    "            annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
    "            images.append(annotated_image)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erreur lors du traitement de l'image {img_path} : {e}\")\n",
    "\n",
    "    return images\n",
    "\n",
    "def display_images_in_grid(images, grid_size=(GRID_SIZE, GRID_SIZE), fig_size=(15, 15)):\n",
    "    fig, axes = plt.subplots(grid_size[0], grid_size[1], figsize=fig_size)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(len(axes)):\n",
    "        if i < len(images):\n",
    "            axes[i].imshow(images[i])\n",
    "            axes[i].axis('off')\n",
    "        else:\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"ğŸ”„ Chargement des images avec annotations...\")\n",
    "annotated_images = load_and_annotate_images()\n",
    "\n",
    "if annotated_images:\n",
    "    print(f\"âœ… {len(annotated_images)} images chargÃ©es et annotÃ©es.\")\n",
    "    display_images_in_grid(annotated_images)\n",
    "else:\n",
    "    print(\"âš ï¸ Aucune image chargÃ©e.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.86  Python-3.12.3 torch-2.5.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "Setup complete  (8 CPUs, 15.8 GB RAM, 270.5/284.9 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import settings\n",
    "\n",
    "# Update a setting\n",
    "settings.update({\n",
    "    'mlflow': False,\n",
    "    'clearml': False,\n",
    "    'comet': False,\n",
    "    'dvc': False,\n",
    "    'hub': False,\n",
    "    'neptune': False,\n",
    "    'raytune': False,\n",
    "    'tensorboard': False,\n",
    "    'wandb': True\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning Modele Yolo :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model_path = os.path.join(\n",
    "    \"runs\", \"detect\", \"YOLOv8_finetune_signature\", \"weights\", \"best.pt\"\n",
    ")\n",
    "save_as = \"finetuned_yolov8_signature_best.pt\"\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    shutil.copy(best_model_path, save_as)\n",
    "    print(f\"âœ… Meilleur modÃ¨le sauvegardÃ© sous : {save_as}\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Aucun fichier best.pt trouvÃ© dans : {best_model_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.91 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.88  Python-3.12.3 torch-2.5.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=Assurances/YOLO_Trained/yolov8sFinal.pt, data=C:/Users/ilyes/intelligIA/datasets/signature/signature.yaml, epochs=50, time=None, patience=8, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=Signature-Detection-FineTune, name=YOLOv8_finetune_signature15, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=True, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=0, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=5e-05, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.1, degrees=10, translate=0.1, scale=0.5, shear=4.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=Signature-Detection-FineTune\\YOLOv8_finetune_signature15\n",
      "Overriding class names with single class.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,135,987 parameters, 11,135,971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: Scanning C:\\Users\\ilyes\\intelligIA\\datasets\\signature\\train\\labels.cache... 143 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 143/143 [00:00<?, ?it/s]Scanning C:\\Users\\ilyes\\intelligIA\\datasets\\signature\\train\\labels.cache... 143 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 143/143 [00:00<?, ?it/s]\n",
      "val: Scanning C:\\Users\\ilyes\\intelligIA\\datasets\\signature\\valid\\labels.cache... 35 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:00<?, ?it/s]Scanning C:\\Users\\ilyes\\intelligIA\\datasets\\signature\\valid\\labels.cache... 35 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to Signature-Detection-FineTune\\YOLOv8_finetune_signature15\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=5e-05' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mSignature-Detection-FineTune\\YOLOv8_finetune_signature15\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G      1.539       1.11      1.822         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [02:11<00:00,  7.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.832      0.943      0.936      0.662\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50         0G      1.217     0.7945      1.551         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:50<00:00,  6.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.899      0.943      0.959      0.774\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50         0G      1.238     0.8526      1.564         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:45<00:00,  5.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.969      0.943       0.99      0.728\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50         0G      1.213     0.8197      1.591         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:38<00:00,  5.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.996      0.943      0.991      0.705\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50         0G      1.243     0.8161       1.56         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:37<00:00,  5.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.941          1      0.986      0.777\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50         0G      1.089     0.7892      1.447         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:37<00:00,  5.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35          1      0.994      0.995      0.681\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50         0G      1.083     0.7191       1.47         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:40<00:00,  5.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.993          1      0.995       0.68\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50         0G       1.11     0.8192      1.446         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:38<00:00,  5.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.917      0.914      0.977      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50         0G      1.063     0.8109        1.4         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:37<00:00,  5.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.931      0.829      0.939      0.622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50         0G      1.162     0.8268      1.491         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:38<00:00,  5.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35       0.98          1      0.995      0.717\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50         0G      1.059     0.6416      1.415         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:37<00:00,  5.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35          1      0.938      0.993      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50         0G      0.986     0.6351      1.354         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:36<00:00,  5.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35          1      0.968      0.994      0.749\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50         0G     0.9009     0.5886      1.261         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:36<00:00,  5.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.997          1      0.995      0.787\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50         0G     0.9575     0.6003       1.32         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:53<00:00,  6.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.996          1      0.995      0.827\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50         0G     0.9897     0.6346      1.319         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:47<00:00,  5.98s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.995          1      0.995      0.756\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50         0G     0.9924     0.6104      1.374         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:44<00:00,  5.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.996          1      0.995      0.726\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50         0G      1.013     0.6256      1.316         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:47<00:00,  5.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.967          1      0.994      0.619\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50         0G     0.9557     0.6273      1.344          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:46<00:00,  5.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.959      0.971      0.991      0.744\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50         0G     0.9022     0.5726      1.302         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:46<00:00,  5.91s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.944          1      0.993      0.728\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50         0G     0.8397     0.5563      1.229         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:46<00:00,  5.90s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.966      0.971      0.987      0.762\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50         0G     0.8957     0.5596      1.296         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:48<00:00,  6.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.997          1      0.995      0.691\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50         0G     0.9545     0.6186      1.332         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:46<00:00,  5.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.974          1      0.995      0.718\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 8 epochs. Best results observed at epoch 14, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=8) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "22 epochs completed in 0.677 hours.\n",
      "Optimizer stripped from Signature-Detection-FineTune\\YOLOv8_finetune_signature15\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from Signature-Detection-FineTune\\YOLOv8_finetune_signature15\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating Signature-Detection-FineTune\\YOLOv8_finetune_signature15\\weights\\best.pt...\n",
      "Ultralytics 8.3.88  Python-3.12.3 torch-2.5.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.996          1      0.995      0.827\n",
      "Speed: 2.5ms preprocess, 120.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mSignature-Detection-FineTune\\YOLOv8_finetune_signature15\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–â–ƒâ–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…</td></tr><tr><td>lr/pg1</td><td>â–â–ƒâ–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…</td></tr><tr><td>lr/pg2</td><td>â–â–ƒâ–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…</td></tr><tr><td>metrics/mAP50(B)</td><td>â–â–„â–‡â–‡â–‡â–ˆâ–ˆâ–†â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ</td></tr><tr><td>metrics/mAP50-95(B)</td><td>â–ƒâ–†â–…â–„â–†â–„â–„â–â–‚â–…â–„â–†â–‡â–ˆâ–†â–…â–‚â–…â–…â–†â–„â–ˆ</td></tr><tr><td>metrics/precision(B)</td><td>â–â–„â–‡â–ˆâ–†â–ˆâ–ˆâ–…â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–‡â–ˆâ–ˆ</td></tr><tr><td>metrics/recall(B)</td><td>â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–…â–â–ˆâ–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆ</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>train/box_loss</td><td>â–ˆâ–…â–…â–…â–…â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–‚</td></tr><tr><td>train/cls_loss</td><td>â–ˆâ–„â–…â–„â–„â–„â–ƒâ–„â–„â–„â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚</td></tr><tr><td>train/dfl_loss</td><td>â–ˆâ–…â–…â–…â–…â–„â–„â–„â–ƒâ–„â–ƒâ–‚â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚</td></tr><tr><td>val/box_loss</td><td>â–†â–ƒâ–„â–‡â–â–‡â–…â–„â–ˆâ–„â–‡â–„â–‚â–â–ƒâ–„â–„â–ƒâ–„â–ƒâ–„â–‚</td></tr><tr><td>val/cls_loss</td><td>â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ˆâ–ˆâ–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚</td></tr><tr><td>val/dfl_loss</td><td>â–„â–â–ƒâ–†â–â–†â–„â–‡â–ˆâ–ƒâ–…â–ƒâ–‚â–â–‚â–ƒâ–„â–‚â–ƒâ–â–ƒâ–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.00126</td></tr><tr><td>lr/pg1</td><td>0.00126</td></tr><tr><td>lr/pg2</td><td>0.00126</td></tr><tr><td>metrics/mAP50(B)</td><td>0.995</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.82719</td></tr><tr><td>metrics/precision(B)</td><td>0.99561</td></tr><tr><td>metrics/recall(B)</td><td>1</td></tr><tr><td>model/GFLOPs</td><td>28.647</td></tr><tr><td>model/parameters</td><td>11135987</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>137.956</td></tr><tr><td>train/box_loss</td><td>0.95451</td></tr><tr><td>train/cls_loss</td><td>0.61864</td></tr><tr><td>train/dfl_loss</td><td>1.3324</td></tr><tr><td>val/box_loss</td><td>0.92959</td></tr><tr><td>val/cls_loss</td><td>0.63845</td></tr><tr><td>val/dfl_loss</td><td>1.11018</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">YOLOv8_finetune_signature14</strong> at: <a href='https://wandb.ai/ilyessais2000-intellig-ia/Signature-Detection-FineTune/runs/tmfs0gxi' target=\"_blank\">https://wandb.ai/ilyessais2000-intellig-ia/Signature-Detection-FineTune/runs/tmfs0gxi</a><br> View project at: <a href='https://wandb.ai/ilyessais2000-intellig-ia/Signature-Detection-FineTune' target=\"_blank\">https://wandb.ai/ilyessais2000-intellig-ia/Signature-Detection-FineTune</a><br>Synced 5 W&B file(s), 21 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250317_021419-tmfs0gxi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.88  Python-3.12.3 torch-2.5.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "Une erreur est survenue : val: Error loading data from C:\\Users\\ilyes\\intelligIA\\datasets\\signature\\test\\images\n",
      "See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "import mlflow\n",
    "from ultralytics import YOLO\n",
    "\n",
    "MODEL_CHECKPOINT = \"Assurances/YOLO_Trained/yolov8sFinal.pt\"\n",
    "DATA_YAML = \"C:/Users/ilyes/intelligIA/datasets/signature/signature.yaml\"\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 8\n",
    "BASE_LR = 5e-5\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"file:///\" + os.path.abspath(\"mlruns\")\n",
    "EXPERIMENT_NAME = \"YOLO_Signature_FineTune\"\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "try:\n",
    "    with mlflow.start_run() as run:\n",
    "        mlflow.log_param(\"model_checkpoint\", MODEL_CHECKPOINT)\n",
    "        mlflow.log_param(\"data_yaml\", DATA_YAML)\n",
    "        mlflow.log_param(\"epochs\", EPOCHS)\n",
    "        mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "        mlflow.log_param(\"base_lr\", BASE_LR)\n",
    "\n",
    "   \n",
    "        model = YOLO(MODEL_CHECKPOINT)\n",
    "\n",
    "      \n",
    "        results = model.train(\n",
    "            data=DATA_YAML,\n",
    "            epochs=EPOCHS,\n",
    "            batch=BATCH_SIZE,\n",
    "            lr0=BASE_LR,\n",
    "            imgsz=640,\n",
    "            single_cls=True,\n",
    "            cos_lr=True,\n",
    "            patience=8,\n",
    "            freeze=0,\n",
    "            degrees=10,\n",
    "            shear=4.0,\n",
    "            hsv_v=0.1,\n",
    "            flipud=0.0,\n",
    "            fliplr=0.5,\n",
    "            scale=0.5,\n",
    "            project=\"Signature-Detection-FineTune\",\n",
    "            name=\"YOLOv8_finetune_signature\",\n",
    "            verbose=False,\n",
    "            save=True         \n",
    "        )\n",
    "\n",
    "        results_test = model.val(\n",
    "            data=DATA_YAML,\n",
    "            split=\"test\",\n",
    "            imgsz=640,\n",
    "            conf=0.25\n",
    "        )\n",
    "        print(\"[INFO] RÃ©sultats test :\", results_test)\n",
    "\n",
    "        try:\n",
    "            mAP50 = results_test.box.maps[0]\n",
    "            mlflow.log_metric(\"mAP50_test\", mAP50)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] Impossible de logguer les mÃ©triques YOLO : {e}\")\n",
    "\n",
    "  \n",
    "        export_name = \"signature_finetuned\"\n",
    "        export_path = model.export(\n",
    "            format=\"torchscript\",\n",
    "            imgsz=640,\n",
    "            name=export_name,\n",
    "            dynamic=False,     \n",
    "            simplify=False     \n",
    "        )\n",
    "\n",
    "\n",
    "        print(f\"[INFO] ModÃ¨le exportÃ© en TorchScript : {export_path}\")\n",
    "\n",
    "      \n",
    "        if os.path.exists(export_path):\n",
    "            mlflow.log_artifact(export_path, artifact_path=\"model\")\n",
    "            print(f\"[INFO] ModÃ¨le .pt logguÃ© dans MLflow : {export_path}\")\n",
    "        else:\n",
    "            print(\"[WARNING] Export .pt introuvable.\")\n",
    "\n",
    "        print(\"[INFO] Fin du run MLflow :\", run.info.run_id)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Une erreur est survenue :\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.17.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnx\n",
    "onnx.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.88  Python-3.12.3 torch-2.5.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\Y'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\Y'\n",
      "C:\\Users\\ilyes\\AppData\\Local\\Temp\\ipykernel_31364\\4003746343.py:4: SyntaxWarning: invalid escape sequence '\\Y'\n",
      "  MODEL_PT = \"Signature-Detection-FineTune\\YOLOv8_finetune_signature7\\weights\\llest.pt\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'Signature-Detection-FineTune\\YOLOv8_finetune_signature7\\weights\\llest.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (21.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.48...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.4s, saved as 'Signature-Detection-FineTune\\YOLOv8_finetune_signature7\\weights\\llest.onnx' (42.7 MB)\n",
      "\n",
      "Export complete (3.0s)\n",
      "Results saved to \u001b[1mC:\\Users\\ilyes\\intelligIA\\Signature-Detection-FineTune\\YOLOv8_finetune_signature7\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=Signature-Detection-FineTune\\YOLOv8_finetune_signature7\\weights\\llest.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=Signature-Detection-FineTune\\YOLOv8_finetune_signature7\\weights\\llest.onnx imgsz=640 data=C:/Users/ilyes/intelligIA/datasets/signature/signature.yaml  \n",
      "Visualize:       https://netron.app\n",
      "ModÃ¨le ONNX gÃ©nÃ©rÃ© : Signature-Detection-FineTune\\YOLOv8_finetune_signature7\\weights\\llest.onnx\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "MODEL_PT = \"Signature-Detection-FineTune\\YOLOv8_finetune_signature7\\weights\\llest.pt\" \n",
    "\n",
    "\n",
    "model = YOLO(MODEL_PT)\n",
    "\n",
    "onnx_path = model.export(\n",
    "    format=\"onnx\",\n",
    "    opset=12,\n",
    "    imgsz=640,\n",
    "    dynamic=False,\n",
    "    name=\"signature_finetuned_onnx\"\n",
    ")\n",
    "\n",
    "print(f\"ModÃ¨le ONNX gÃ©nÃ©rÃ© : {onnx_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
