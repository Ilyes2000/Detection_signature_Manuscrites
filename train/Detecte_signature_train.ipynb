{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection signature : Train & Evaluation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📄 **Détection de Signatures - Entraînement et Évaluation**\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 **Objectif du projet**  \n",
    "L'objectif initial est de pouvoir **automatiser la reconnaissance de documents signés ou non signés**.  \n",
    "Cela permettrait :  \n",
    "✅ D'accélérer le traitement automatique des documents.  \n",
    "✅ D'améliorer la précision de la détection de signatures.  \n",
    "✅ De faciliter la vérification d'authenticité des documents.  \n",
    "\n",
    "---\n",
    "\n",
    "## 🔎 **Contexte du projet**  \n",
    "Les signatures manuscrites ne sont **pas des classes** déjà présentes dans les jeux de données utilisés pour l'entraînement initial des modèles de détection d'objets.  \n",
    "Ainsi, une phase de **fine-tuning** est nécessaire pour ajuster les modèles :  \n",
    "✔️ Tirer parti des poids déjà pré-entraînés sur des bases d'images générales.  \n",
    "✔️ Affiner le modèle pour détecter spécifiquement des signatures dans des documents.  \n",
    "✔️ Améliorer la capacité du modèle à extraire des caractéristiques spécifiques aux signatures.  \n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 **Pourquoi le Fine-Tuning est Nécessaire ?**  \n",
    "Les modèles de détection d'objets (comme YOLO, Faster R-CNN, RetinaNet, etc.) sont généralement pré-entraînés sur des jeux de données comme **COCO** ou **ImageNet**.  \n",
    "👉 Cependant, ces jeux de données ne contiennent pas de classes spécifiques aux signatures manuscrites.  \n",
    "👉 Un ajustement est donc nécessaire pour adapter le modèle à ce cas d'usage particulier.  \n",
    "\n",
    "### ➡️ **Avantages du Fine-Tuning :**  \n",
    "✅ Accélération du processus d'entraînement grâce aux poids déjà pré-entraînés.  \n",
    "✅ Extraction de caractéristiques générales des images (formes, textures, motifs).  \n",
    "✅ Adaptation rapide à un domaine spécifique (reconnaissance de signatures).  \n",
    "✅ Optimisation plus rapide et plus efficace.  \n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ **Approche Technique**  \n",
    "### 1. **Préparation des Données :**  \n",
    "- Extraction des signatures depuis des fichiers PDF.  \n",
    "- Annotation manuelle des signatures dans les documents (bounding boxes).  \n",
    "- Augmentation des données pour enrichir le dataset (rotation, recadrage, etc.).  \n",
    "\n",
    "### 2. **Modèles Utilisés :**  \n",
    "- 🔹 **YOLOv8** \n",
    "- 🔹 **YOLOv11**  \n",
    "\n",
    "\n",
    "### 3. **Stratégie de Fine-Tuning :**  \n",
    "✔️ Chargement des poids pré-entraînés.  \n",
    "✔️ Congélation des premières couches du modèle (pour conserver les caractéristiques générales).  \n",
    "✔️ Ajustement des couches finales pour apprendre la spécificité des signatures.  \n",
    "✔️ Entraînement du modèle avec des hyperparamètres adaptés :  \n",
    "- Taux d'apprentissage (`learning rate`)  \n",
    "- Taille de batch (`batch size`)  \n",
    "- Nombre d'époques (`epochs`)  \n",
    "✔️ Ajustement de la fonction de perte pour une meilleure convergence.  \n",
    "\n",
    "---\n",
    "\n",
    "## 📊 **Évaluation des Modèles**  \n",
    "- **Précision (Precision)** – capacité à ne détecter que des signatures réelles.  \n",
    "- **Rappel (Recall)** – capacité à détecter toutes les signatures présentes.  \n",
    "- **mAP (mean Average Precision)** – score moyen global de détection.  \n",
    "- **F1-Score** – équilibre entre la précision et le rappel.  \n",
    "- **Taux de faux positifs/négatifs** – capacité à éviter les erreurs de détection.  \n",
    "\n",
    "---\n",
    "\n",
    "## 🏆 **Résultats Attendus**  \n",
    "✅ Détection fiable des signatures dans différents types de documents.  \n",
    "✅ Réduction du nombre de faux positifs et faux négatifs.  \n",
    "✅ Optimisation rapide grâce à l'utilisation de poids pré-entraînés.  \n",
    "✅ Automatisation du processus de validation de documents signés.  \n",
    "\n",
    "---\n",
    "\n",
    "## 🚨 **Défis Potentiels**  \n",
    "⚠️ Mauvaise qualité des signatures (floues, partielles, surimposées).  \n",
    "⚠️ Variabilité des styles de signature (taille, forme, orientation).  \n",
    "⚠️ Présence de bruits visuels (tampons, annotations).  \n",
    "⚠️ Équilibre entre la précision et le rappel.  \n",
    "\n",
    "---\n",
    "\n",
    "## ✅ **Prochaines Étapes**  \n",
    "🔎 Évaluer la performance des modèles après fine-tuning.  \n",
    "📉 Comparer les résultats des différents modèles.  \n",
    "🧪 Ajuster les hyperparamètres pour améliorer la convergence.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: supervision in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (0.25.1)\n",
      "Collecting roboflow\n",
      "  Downloading roboflow-1.1.56-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.7 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (1.3.1)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (0.7.1)\n",
      "Requirement already satisfied: matplotlib>=3.6.0 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (1.26.4)\n",
      "Requirement already satisfied: opencv-python>=4.5.5.64 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=9.4 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (2.32.3)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (1.14.1)\n",
      "Requirement already satisfied: tqdm>=4.62.3 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from supervision) (4.66.5)\n",
      "Requirement already satisfied: certifi in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from roboflow) (2024.12.14)\n",
      "Collecting idna==3.7 (from roboflow)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: cycler in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from roboflow) (1.4.7)\n",
      "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Collecting python-dotenv (from roboflow)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: six in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from roboflow) (1.26.20)\n",
      "Collecting requests-toolbelt (from roboflow)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting filetype (from roboflow)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from matplotlib>=3.6.0->supervision) (4.55.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from matplotlib>=3.6.0->supervision) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from matplotlib>=3.6.0->supervision) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from requests>=2.26.0->supervision) (3.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ilyes\\intelligia\\myenv\\lib\\site-packages (from tqdm>=4.62.3->supervision) (0.4.6)\n",
      "Downloading roboflow-1.1.56-py3-none-any.whl (83 kB)\n",
      "Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Installing collected packages: filetype, python-dotenv, opencv-python-headless, idna, requests-toolbelt, roboflow\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\ilyes\\intelligIA\\myenv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\ilyes\\intelligIA\\myenv\\Lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Accès refusé: 'c:\\\\Users\\\\ilyes\\\\intelligIA\\\\myenv\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade supervision roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "import math\n",
    "import yaml\n",
    "from typing import Optional\n",
    "import requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import gc\n",
    "import numpy as np\n",
    "from random import randrange, sample\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import dataclasses\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, List, Type, Union, Callable\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import uuid\n",
    "\n",
    "from IPython.display import Markdown, display, Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import supervision as sv\n",
    "import glob\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(\"logger\")\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📂 **Dataset**\n",
    "\n",
    "---\n",
    "\n",
    "## **Présentation du Dataset**  \n",
    "Ce dataset a été développé pour entraîner des modèles de détection de signatures manuscrites dans divers types de documents.  \n",
    "Il combine des données provenant de plusieurs sources publiques et d'un dataset personnalisé développé par **IntelligIA**.  \n",
    "Les données ont été soigneusement annotées et unifiées dans un format standardisé **COCO JSON** pour une compatibilité optimale avec les modèles de détection d'objets.  \n",
    "\n",
    "---\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td style=\"text-align: center; padding: 10px;\">\n",
    "      <a href=\"https://universe.roboflow.com/tech-ysdkk/signature-detection-hlx8j\">\n",
    "        <img src=\"https://app.roboflow.com/images/download-dataset-badge.svg\">\n",
    "      </a>\n",
    "    </td>\n",
    "    <td style=\"text-align: center; padding: 10px;\">\n",
    "      <a href=\"https://huggingface.co/datasets/tech4humans/signature-detection\">\n",
    "        <img src=\"https://huggingface.co/datasets/huggingface/badges/resolve/main/dataset-on-hf-md.svg\" alt=\"Dataset on HF\">\n",
    "      </a>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "---\n",
    "\n",
    "## **Composantes du Dataset**  \n",
    "### 🔹 **1. Tobacco800** ([Lien](https://paperswithcode.com/dataset/tobacco-800))  \n",
    "- Un sous-ensemble du **Complex Document Image Processing (CDIP)** Test Collection.  \n",
    "- Contient des images scannées de documents liés à l'industrie du tabac.  \n",
    "- Créé par l'Institut de Technologie de l'Illinois (IIT).  \n",
    "- **Format :** TIFF converti en COCO JSON.  \n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **2. Signatures-XC8UP** ([Lien](https://universe.roboflow.com/roboflow-100/signatures-xc8up))  \n",
    "- Fait partie de **Roboflow 100**, une initiative d'Intel.  \n",
    "- Contient **368 images annotées** pour la détection de signatures manuscrites.  \n",
    "- Les annotations sont en format **COCO JSON**.  \n",
    "- **Types de signatures :** Variété de styles et de tailles.  \n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **3. Dataset IntelligIA**  \n",
    "- Créé et annoté manuellement par **IntelligIA** pour une tâche spécifique de détection de signatures dans des documents professionnels.  \n",
    "- Inclut **178 images** de documents (format PDF, JPEG et PNG).  \n",
    "- Les annotations sont en **format COCO JSON**.  \n",
    "- Les données sont issues de documents réels (assurances, contrats, formulaires).  \n",
    "- **Types de signatures détectées :**  \n",
    "    - Signatures manuscrites.  \n",
    "    - Signatures électroniques.  \n",
    "    - Signatures partiellement visibles ou incomplètes.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Détails du Dataset**  \n",
    "| Type de Données | Nombre d'Images | % du Total |\n",
    "|-----------------|------------------|------------|\n",
    "| **Entraînement** | 1 980 | 70% |\n",
    "| **Validation**   | 420   | 15% |\n",
    "| **Test**         | 419   | 15% |\n",
    "| **Total**        | 2 819 | 100% |\n",
    "\n",
    "---\n",
    "\n",
    "## **Format du Dataset**  \n",
    "✅ **Format :** COCO JSON  \n",
    "✅ **Taille des fichiers :** 1.2 Go  \n",
    "✅ **Licence :** Apache 2.0  \n",
    "\n",
    "---\n",
    "\n",
    "## 📊 **Pourquoi ces Datasets ?**  \n",
    "✅ Le dataset **Tobacco800** permet une meilleure reconnaissance de texte complexe dans des documents professionnels.  \n",
    "✅ Le dataset **Signatures-XC8UP** améliore la reconnaissance de signatures manuscrites.  \n",
    "✅ Le dataset **IntelligIA** permet une adaptation à des documents réels professionnels (assurances, contrats).  \n",
    "✅ La diversité des données permet au modèle d'apprendre à détecter des signatures dans différents contextes, styles et qualités d'image.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Datasets yolo format to coco json format :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Conversion YOLO → COCO en cours...\n",
      "🔎 Traitement de l'image : 01 Arr╦åtÔÇÜ de permis de construire_page-0001.jpg\n",
      "🔎 Traitement de l'image : 01 Arr╦åtÔÇÜ permis de construire_BESSAN_page-0002.jpg\n",
      "🔎 Traitement de l'image : 01 Arr╦åtÔÇÜ permis de construire_BESSAN_page-0005.jpg\n",
      "🔎 Traitement de l'image : 01 Arr╦åtÔÇÜ permis de construire_BESSAN_page-0009.jpg\n",
      "🔎 Traitement de l'image : 01 Arr╦åtÔÇÜ permis de construire_BESSAN_page-0011.jpg\n",
      "🔎 Traitement de l'image : 01 Arr╦åtÔÇÜ permis de construire_BESSAN_page-0015.jpg\n",
      "🔎 Traitement de l'image : 01 Arr╦åtÔÇÜ permis de construire_BESSAN_page-0017.jpg\n",
      "🔎 Traitement de l'image : 01 Arr╦åtÔÇÜ permis de construire_BESSAN_page-0025.jpg\n",
      "🔎 Traitement de l'image : 01. Arr╦åtÔÇÜ de permis de construire Arles_page-0003.jpg\n",
      "🔎 Traitement de l'image : 01. Arr╦åtÔÇÜ de permis de construire Arles_page-0008.jpg\n",
      "🔎 Traitement de l'image : 01. Arr╦åtÔÇÜ de permis de construire Arles_page-0011.jpg\n",
      "🔎 Traitement de l'image : 01. Arr╦åtÔÇÜ de permis de construire Arles_page-0015.jpg\n",
      "🔎 Traitement de l'image : 01. Arr╦åtÔÇÜ de permis de construire Arles_page-0016.jpg\n",
      "🔎 Traitement de l'image : 01. Arr╦åtÔÇÜ de permis de construire Arles_page-0017.jpg\n",
      "🔎 Traitement de l'image : 01. Arr╦åtÔÇÜ de permis de construireB0134-Bayonne_pages-to-jpg-0002.jpg\n",
      "🔎 Traitement de l'image : 01. Arr╦åtÔÇÜ de permis de construire_ARLES BAYONNE_page-0002.jpg\n",
      "🔎 Traitement de l'image : 03. Attestation de non recours - TA Arles_page-0001.jpg\n",
      "🔎 Traitement de l'image : 04 Cerfa signÔÇÜ - PC Vendargue 2-M0054_page-0008.jpg\n",
      "🔎 Traitement de l'image : 04 Cerfa signÔÇÜ - PC Vendargue 2-M0054_page-0018.jpg\n",
      "🔎 Traitement de l'image : 2020 05 15 - arr╦åtÔÇÜ dÔÇÜclaration prÔÇÜalable travaux CrÔÇÜteil DP 94028 20 C4023_page-0001.jpg\n",
      "🔎 Traitement de l'image : 2020 05 15 - arr╦åtÔÇÜ dÔÇÜclaration prÔÇÜalable travaux CrÔÇÜteil DP 94028 20 C4023_page-0003.jpg\n",
      "🔎 Traitement de l'image : 2020 05 15 - arr╦åtÔÇÜ dÔÇÜclaration prÔÇÜalable travaux CrÔÇÜteil DP 94028 20 C4023_page-0004.jpg\n",
      "🔎 Traitement de l'image : 2020 05 15 - arr╦åtÔÇÜ dÔÇÜclaration prÔÇÜalable travaux CrÔÇÜteil DP 94028 20 C4023_page-0005.jpg\n",
      "🔎 Traitement de l'image : 2020 05 15 - arr╦åtÔÇÜ dÔÇÜclaration prÔÇÜalable travaux CrÔÇÜteil DP 94028 20 C4023_page-0012.jpg\n",
      "🔎 Traitement de l'image : 2020 05 15 - arr╦åtÔÇÜ dÔÇÜclaration prÔÇÜalable travaux CrÔÇÜteil DP 94028 20 C4023_page-0019.jpg\n",
      "🔎 Traitement de l'image : 2020 06 18 - 1er PV de constat d'affichage_page-0005.jpg\n",
      "🔎 Traitement de l'image : 2020 07 20 - 2þó║e PV de constat d'affichage_page-0006.jpg\n",
      "🔎 Traitement de l'image : 2020 08 18 - 3þó║e PV de constat d'affichage_page-0006.jpg\n",
      "🔎 Traitement de l'image : AFFICHAGE 1ER PASSAGE_MARSEILLE_page-0005.jpg\n",
      "🔎 Traitement de l'image : Atterstation non recours des tiers BOE_page-0001.jpg\n",
      "🔎 Traitement de l'image : Attestation Conformite PC18Y0009 Aubergenville_page-0001.jpg\n",
      "🔎 Traitement de l'image : Attestation conformitÔÇÜ LOON PLAGE_page-0001.jpg\n",
      "🔎 Traitement de l'image : Attestation conformitÔÇÜ LOON PLAGE_page-0002.jpg\n",
      "🔎 Traitement de l'image : Attestation de non recours au PC (TA)_BOE_page-0001.jpg\n",
      "🔎 Traitement de l'image : Attestation de non recours TA - Loom-Plage_DUNKERQUE_page-0001.jpg\n",
      "🔎 Traitement de l'image : Attestation de non recours TA-1_Beziers_page-0001.jpg\n",
      "🔎 Traitement de l'image : Attestation de non recours TA-9Baziege_page-0001.jpg\n",
      "🔎 Traitement de l'image : Attestation non contestation PC 1 Bayonne_27 06 2022_page-0001.jpg\n",
      "🔎 Traitement de l'image : Attestation non contestation PC 2 Bayonne_27 06 2022_page-0001.jpg\n",
      "🔎 Traitement de l'image : Attestation non recours TA - Marseille 2_page-0001.jpg\n",
      "🔎 Traitement de l'image : AUBERGENVILLE - DAACT - 2021_page-0002.jpg\n",
      "🔎 Traitement de l'image : AUBERGENVILLE - DAACT - 2021_page-0004.jpg\n",
      "🔎 Traitement de l'image : Avenant contrat HEL 2025 - Signé_page-0002.jpg\n",
      "🔎 Traitement de l'image : BESSAN - Certificat de non opposition conformitÔÇÜ des travaux 17-11-2022_page-0001.jpg\n",
      "🔎 Traitement de l'image : BESSAN 1 - RÔÇÜcÔÇÜpissÔÇÜ DAACT - PC 34031 19 K0016 - 01.06.22_page-0001.jpg\n",
      "🔎 Traitement de l'image : BESSAN 1 - RÔÇÜcÔÇÜpissÔÇÜ DAACT - PC 34031 19 K0016 - 01.06.22_page-0002.jpg\n",
      "🔎 Traitement de l'image : BESSAN-Certificat de non opposition conformitÔÇÜ des travaux 17-11-2022_page-0001.jpg\n",
      "🔎 Traitement de l'image : Cartificat de conformitÔÇÜ 25.01.2010_page-0001.jpg\n",
      "🔎 Traitement de l'image : certificat conformitÔÇÜ immeuble voisin 2013_page-0001.jpg\n",
      "🔎 Traitement de l'image : DAACT - BAYONNE 2 - Cerfa - Avis de rÔÇÜception 12.01.22_page-0001.jpg\n",
      "🔎 Traitement de l'image : DAACT immeuble voisin 2012_page-0002.jpg\n",
      "🔎 Traitement de l'image : DAT 10 avril 1985_page-0001.jpg\n",
      "🔎 Traitement de l'image : DOC bessan PC 2_page-0001.jpg\n",
      "🔎 Traitement de l'image : DOC bessan PC 2_page-0003.jpg\n",
      "🔎 Traitement de l'image : DROC 1er novembre 1984_page-0001.jpg\n",
      "🔎 Traitement de l'image : DROC 3 juin 1985_page-0001.jpg\n",
      "🔎 Traitement de l'image : dÔÇÜclaration achS╠îvement travaux 13 septembre 1985_page-0001.jpg\n",
      "🔎 Traitement de l'image : DÔÇÜclaration achS╠îvement travaux 3 juin 1985_page-0001.jpg\n",
      "🔎 Traitement de l'image : DÔÇÜclaration d'ouverture de chantier du 20.03.1975_page-0001.jpg\n",
      "🔎 Traitement de l'image : Permis de construire_CASTELNAU bis_page-0002.jpg\n",
      "🔎 Traitement de l'image : Permis de construire_CASTELNAU_page-0002.jpg\n",
      "🔎 Traitement de l'image : Permis de construire_CASTELNAU_page-0004.jpg\n",
      "🔎 Traitement de l'image : Permis de construire_CLERMONT_pages-to-jpg-0001.jpg\n",
      "🔎 Traitement de l'image : Permis de construire_CLERMONT_pages-to-jpg-0003.jpg\n",
      "🔎 Traitement de l'image : Permis de construire_DUNKERQUE_page-0001.jpg\n",
      "🔎 Traitement de l'image : Permis de construire_DUNKERQUE_page-0002.jpg\n",
      "🔎 Traitement de l'image : Permis de construire_DUNKERQUE_page-0003.jpg\n",
      "🔎 Traitement de l'image : Permis de construire_LONGVIC_page-0003.jpg\n",
      "🔎 Traitement de l'image : Permis de construire_LONGVIC_page-0005.jpg\n",
      "🔎 Traitement de l'image : Permis de construire_LONGVIC_page-0008.jpg\n",
      "🔎 Traitement de l'image : Permis de construire_LONGVIC_page-0010.jpg\n",
      "🔎 Traitement de l'image : Permis de construire_LONGVIC_page-0011.jpg\n",
      "🔎 Traitement de l'image : Resotainer_Beziers DROC valide_page-0001.jpg\n",
      "🔎 Traitement de l'image : Resotainer_Beziers DROC valide_page-0002.jpg\n",
      "🔎 Traitement de l'image : Screenshot-2024-07-30-094419_png.rf.2d363b9b0ee22beccd670b736beeccaa.jpg\n",
      "🔎 Traitement de l'image : signed_agreement_1.jpg\n",
      "🔎 Traitement de l'image : yrz52d00_png.rf.a77b190c8f35247852ca7313ca12b92d.jpg\n",
      "🔎 Traitement de l'image : 10_page_77.png\n",
      "🔎 Traitement de l'image : 15_page_1.png\n",
      "🔎 Traitement de l'image : 15_page_16.png\n",
      "🔎 Traitement de l'image : 16_page_1.png\n",
      "🔎 Traitement de l'image : 17_page_1.png\n",
      "🔎 Traitement de l'image : 17_page_16.png\n",
      "🔎 Traitement de l'image : 18_page_2.png\n",
      "🔎 Traitement de l'image : 19_page_1.png\n",
      "🔎 Traitement de l'image : 1_page_1.png\n",
      "🔎 Traitement de l'image : 1_page_75.png\n",
      "🔎 Traitement de l'image : 2023 Attestation BAYONNE_page_1.png\n",
      "🔎 Traitement de l'image : 2023 Attestation BÕÇåiers_page_1.png\n",
      "🔎 Traitement de l'image : 2023 Attestation Marseille_page_1.png\n",
      "🔎 Traitement de l'image : 22_page_1.png\n",
      "🔎 Traitement de l'image : 24_page_11.png\n",
      "🔎 Traitement de l'image : 25_page_1.png\n",
      "🔎 Traitement de l'image : 26_page_1.png\n",
      "🔎 Traitement de l'image : 27_page_1.png\n",
      "🔎 Traitement de l'image : 29_page_1.png\n",
      "🔎 Traitement de l'image : 2_page_1.png\n",
      "🔎 Traitement de l'image : 30_page_1.png\n",
      "🔎 Traitement de l'image : 32_page_1.png\n",
      "🔎 Traitement de l'image : 33_page_1.png\n",
      "🔎 Traitement de l'image : 35_page_1.png\n",
      "🔎 Traitement de l'image : 36_page_1.png\n",
      "🔎 Traitement de l'image : 38_page_1.png\n",
      "🔎 Traitement de l'image : 39_page_1.png\n",
      "🔎 Traitement de l'image : 40_page_1.png\n",
      "🔎 Traitement de l'image : 41_page_1.png\n",
      "🔎 Traitement de l'image : 42_page_1.png\n",
      "🔎 Traitement de l'image : 43_page_1.png\n",
      "🔎 Traitement de l'image : 45_page_1.png\n",
      "🔎 Traitement de l'image : 46_page_1.png\n",
      "🔎 Traitement de l'image : 47_page_1.png\n",
      "🔎 Traitement de l'image : 48_page_1.png\n",
      "🔎 Traitement de l'image : 4_page_9.png\n",
      "🔎 Traitement de l'image : 50_page_1.png\n",
      "🔎 Traitement de l'image : 51_page_1.png\n",
      "🔎 Traitement de l'image : 52_page_1.png\n",
      "🔎 Traitement de l'image : 53_page_1.png\n",
      "🔎 Traitement de l'image : 55_page_1.png\n",
      "🔎 Traitement de l'image : 56_page_1.png\n",
      "🔎 Traitement de l'image : 57_page_1.png\n",
      "🔎 Traitement de l'image : 59_page_1.png\n",
      "🔎 Traitement de l'image : 5_page_1.png\n",
      "🔎 Traitement de l'image : 5_page_5.png\n",
      "🔎 Traitement de l'image : 61_page_1.png\n",
      "🔎 Traitement de l'image : 62_page_1.png\n",
      "🔎 Traitement de l'image : 63_page_1.png\n",
      "🔎 Traitement de l'image : 64_page_1.png\n",
      "🔎 Traitement de l'image : 66_page_1.png\n",
      "🔎 Traitement de l'image : 67_page_1.png\n",
      "🔎 Traitement de l'image : 69_page_1.png\n",
      "🔎 Traitement de l'image : 70_page_1.png\n",
      "🔎 Traitement de l'image : 72_page_1.png\n",
      "🔎 Traitement de l'image : 73_page_1.png\n",
      "🔎 Traitement de l'image : 7_page_16.png\n",
      "🔎 Traitement de l'image : 8_page_1.png\n",
      "🔎 Traitement de l'image : 9_page_1.png\n",
      "🔎 Traitement de l'image : 9_page_3.png\n",
      "🔎 Traitement de l'image : AREAS - RESOTAINER - Avenant 2021_page_3.png\n",
      "🔎 Traitement de l'image : AREAS - RESOTAINER - Avenant 2021_page_5.png\n",
      "🔎 Traitement de l'image : AREAS - RESOTAINER BESSAN - Attestation d_Assurance 2021_page_1.png\n",
      "🔎 Traitement de l'image : AREAS - RESOTAINER BOE - Attestation d'Assurance 2021_BOE_page_1.png\n",
      "🔎 Traitement de l'image : AREAS - RESOTAINER BOE - Attestation d_Assurance 2021_page_1.png\n",
      "🔎 Traitement de l'image : AREAS - RESOTAINER BOIS GRENIER - Attestation d'Assurance 2021_page_1.png\n",
      "🔎 Traitement de l'image : AREAS - RESOTAINER BOIS GRENIER - Attestation d_Assurance 2021_page_1.png\n",
      "🔎 Traitement de l'image : ARNAL - Attestation d'Assurance - RC 2021_page_3.png\n",
      "🔎 Traitement de l'image : Assurances AREAS - RESOTAINER BESSAN - Attestation d'Assurance 2021_page_1.png\n",
      "🔎 Traitement de l'image : Attestation Areas Site Bessan 2_page_1.png\n",
      "🔎 Traitement de l'image : attestation assurance multirisque immeuble  6 mai 2019 29 Casanova_page_1.png\n",
      "🔎 Traitement de l'image : attestation assurance multirisque immeuble 17 octobre 2019 Casanova_page_1.png\n",
      "🔎 Traitement de l'image : Attestation assurance multirisque professionnelle 17 octobre 2019 Casanova_page_1.png\n",
      "🔎 Traitement de l'image : attestation assurance RC 27.12.2019_page_1.png\n",
      "🔎 Traitement de l'image : attestation de FIP charges a jour_page_1.png\n",
      "🔎 Traitement de l'image : Attestation immeuble 2024.signed_page_1.png\n",
      "🔎 Traitement de l'image : Attestation immeuble SARL HADAR 2025_page_1.png\n",
      "🔎 Traitement de l'image : Attestation MRP contrat n├©10612066704.signed_page_1.png\n",
      "🔎 Traitement de l'image : Attestation MRP contrat n├©1693112904.signed_page_1.png\n",
      "🔎 Traitement de l'image : Attestation non sinistralitÔÇÜ SARL HADAR MRP contrat n├©10612066704_page_1.png\n",
      "🔎 Traitement de l'image : Attestation non sinistralitÔÇÜ SARL HADAR MRP_page_1.png\n",
      "🔎 Traitement de l'image : attestation_page_1.png\n",
      "🔎 Traitement de l'image : CASANOVA - Attestation multirisque_page_1.png\n",
      "🔎 Traitement de l'image : CLERMONT L HERAULT 2024_page_1.png\n",
      "🔎 Traitement de l'image : Conditions particulieres  multirisque professionnelle  Casanova fevrier 2012_page_12.png\n",
      "🔎 Traitement de l'image : Contrat assurance multirisque - AXA copropriÔÇÜtÔÇÜ (29 Danielle casanova 75001 Paris (002)_page_5.png\n",
      "🔎 Traitement de l'image : CP signÔÇÜ MRP -HADAR contrat fait en 2019_page_9.png\n",
      "🔎 Traitement de l'image : FIN TRAVAUX MARSEILLE PC01_page_2.png\n",
      "🔎 Traitement de l'image : FIN TRAVAUX MARSEILLE PC02_page_2.png\n",
      "🔎 Traitement de l'image : GAN - RESOTAINER BAYONNE - Attestation d'assurance 2022 prime payÔÇÜe_page_1.png\n",
      "🔎 Traitement de l'image : GAN - RESOTAINER TOULOUSE - Attestation d'assurance 2022 prime payÔÇÜe + PE_page_1.png\n",
      "🔎 Traitement de l'image : MAJESTIC PASSY  ATTESTATION _11225583804_page_1.png\n",
      "🔎 Traitement de l'image : MAJESTIC PASSY NOUVELLES DISPOSITIONS PARTICULIERES FONCIERE PARIS PASSY_page_2.png\n",
      "🔎 Traitement de l'image : MAJESTIC PASSY NOUVELLES DISPOSITIONS PARTICULIERES FONCIERE PARIS PASSY_page_9.png\n",
      "🔎 Traitement de l'image : MRI Flandre - CP AFM_page_3.png\n",
      "🔎 Traitement de l'image : POINT DU JOUR  Dispositions particulières GENERALI du 15 05 2020_page_1.png\n",
      "🔎 Traitement de l'image : POINT DU JOUR Attestation d'assurance du 06 10 2022_page_1.png\n",
      "🔎 Traitement de l'image : TOSCA II - 2022-07 SHIF - Police CHUBB FRPAKA64274_page_77.png\n",
      "🔎 Traitement de l'image : TOSCA II _2023.03.23-Attestation_de_paiement_de_la_prime_(HÔTEL_L’INTERCONTINENTAL)_page_1.png\n",
      "✅ Fichier COCO JSON sauvegardé : dataset_coco.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import sys\n",
    "import io\n",
    "\n",
    "\n",
    "IMG_DIR = 'datasets/signature/train/images/'    \n",
    "LABEL_DIR = 'datasets/signature/train/labels/'   \n",
    "OUTPUT_JSON = 'dataset_coco.json'\n",
    "\n",
    "\n",
    "CATEGORIES = [\n",
    "    {\"id\": 0, \"name\": \"signature\"}\n",
    "]\n",
    "\n",
    "\n",
    "images = []\n",
    "annotations = []\n",
    "categories = CATEGORIES\n",
    "annotation_id = 1\n",
    "\n",
    "\n",
    "def sanitize_path(path):\n",
    "    return os.path.normpath(path)\n",
    "\n",
    "\n",
    "def read_image(img_path):\n",
    "    try:\n",
    "\n",
    "        img_path_encoded = os.fsencode(img_path).decode('utf-8')\n",
    "        image = cv2.imdecode(np.fromfile(img_path_encoded, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors de la lecture de l'image {img_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def yolo_to_coco():\n",
    "    global annotation_id\n",
    "\n",
    "  \n",
    "    image_paths = glob.glob(sanitize_path(os.path.join(IMG_DIR, '*.jpg'))) + \\\n",
    "                  glob.glob(sanitize_path(os.path.join(IMG_DIR, '*.png')))\n",
    "\n",
    "    image_id = 1\n",
    "    for img_path in image_paths:\n",
    "        try:\n",
    "            file_name = os.path.basename(img_path)\n",
    "            print(f\"🔎 Traitement de l'image : {file_name}\")\n",
    "\n",
    "    \n",
    "            image = read_image(img_path)\n",
    "            if image is None:\n",
    "                print(f\"❌ Impossible de lire l'image : {img_path}\")\n",
    "                continue\n",
    "\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            images.append({\n",
    "                'id': image_id,\n",
    "                'file_name': file_name,\n",
    "                'height': height,\n",
    "                'width': width\n",
    "            })\n",
    "\n",
    "            label_path_jpg = sanitize_path(os.path.join(LABEL_DIR, file_name.replace('.jpg', '.txt')))\n",
    "            label_path_png = sanitize_path(os.path.join(LABEL_DIR, file_name.replace('.png', '.txt')))\n",
    "            label_path = label_path_jpg if os.path.exists(label_path_jpg) else label_path_png\n",
    "\n",
    "            if os.path.exists(label_path):\n",
    "                with open(label_path, 'r', encoding='utf-8') as f:\n",
    "                    lines = f.readlines()\n",
    "                    for line in lines:\n",
    "                        try:\n",
    "                            class_id, x_center, y_center, w, h = map(float, line.strip().split())\n",
    "\n",
    "                            x = int((x_center - w / 2) * width)\n",
    "                            y = int((y_center - h / 2) * height)\n",
    "                            w = int(w * width)\n",
    "                            h = int(h * height)\n",
    "\n",
    "                            annotations.append({\n",
    "                                'id': annotation_id,\n",
    "                                'image_id': image_id,\n",
    "                                'category_id': int(class_id),\n",
    "                                'bbox': [x, y, w, h],\n",
    "                                'area': w * h,\n",
    "                                'iscrowd': 0\n",
    "                            })\n",
    "\n",
    "                            annotation_id += 1\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(f\"❌ Erreur lors du traitement de l'annotation : {line.strip()} → {e}\")\n",
    "\n",
    "            else:\n",
    "                print(f\"⚠️ Aucun fichier d'annotation trouvé pour l'image : {file_name}\")\n",
    "\n",
    "            image_id += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erreur lors du traitement de l'image {file_name} : {e}\")\n",
    "\n",
    "\n",
    "print(\"🔄 Conversion YOLO → COCO en cours...\")\n",
    "yolo_to_coco()\n",
    "\n",
    "coco_output = {\n",
    "    'images': images,\n",
    "    'annotations': annotations,\n",
    "    'categories': categories\n",
    "}\n",
    "\n",
    "with open(OUTPUT_JSON, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(coco_output, json_file, indent=4)\n",
    "\n",
    "print(f\"✅ Fichier COCO JSON sauvegardé : {OUTPUT_JSON}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display dataset sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Chargement des images avec annotations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 36 images chargées et annotées.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1500 with 36 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "IMG_DIR = 'datasets/signature/train/images'\n",
    "LABEL_DIR = 'datasets/signature/train/labels'\n",
    "GRID_SIZE = 6\n",
    "\n",
    "CLASSES = [\"signature\"]\n",
    "\n",
    "def load_yolo_annotations(label_path, width, height):\n",
    "    annotations = []\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r', encoding='utf-8') as f:  \n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                try:\n",
    "                    class_id, x_center, y_center, w, h = map(float, line.strip().split())\n",
    "                    x = int((x_center - w / 2) * width)\n",
    "                    y = int((y_center - h / 2) * height)\n",
    "                    w = int(w * width)\n",
    "                    h = int(h * height)\n",
    "                    annotations.append({\n",
    "                        'class_id': int(class_id),\n",
    "                        'bbox': [x, y, w, h]\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Erreur lors de la lecture de l'annotation : {e}\")\n",
    "    return annotations\n",
    "\n",
    "def annotate_image(image, annotations):\n",
    "    for ann in annotations:\n",
    "        x, y, w, h = ann['bbox']\n",
    "        class_id = ann['class_id']\n",
    "        label = CLASSES[class_id]\n",
    "        \n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(\n",
    "            image, \n",
    "            label, \n",
    "            (x, y - 10), \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "            0.6, \n",
    "            (0, 255, 0), \n",
    "            2\n",
    "        )\n",
    "    return image\n",
    "\n",
    "def load_and_annotate_images():\n",
    "    images = []\n",
    "    \n",
    "    image_paths = glob.glob(os.path.join(IMG_DIR, '*.jpg')) + glob.glob(os.path.join(IMG_DIR, '*.png'))\n",
    "    \n",
    "    image_paths = [path.replace(\"\\\\\", \"/\") for path in image_paths]\n",
    "    \n",
    "    for img_path in image_paths[:GRID_SIZE * GRID_SIZE]:\n",
    "        try:\n",
    "            file_name = os.path.basename(img_path)\n",
    "            label_path_jpg = os.path.join(LABEL_DIR, file_name.replace('.jpg', '.txt'))\n",
    "            label_path_png = os.path.join(LABEL_DIR, file_name.replace('.png', '.txt'))\n",
    "            label_path = label_path_jpg if os.path.exists(label_path_jpg) else label_path_png\n",
    "\n",
    "            if not os.path.exists(img_path):\n",
    "                print(f\"❌ Fichier introuvable : {img_path}\")\n",
    "                continue\n",
    "\n",
    "           \n",
    "            image = cv2.imdecode(np.fromfile(img_path, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "            if image is None:\n",
    "                print(f\"❌ Erreur lors du chargement de l'image : {img_path}\")\n",
    "                continue\n",
    "\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "           \n",
    "            annotations = load_yolo_annotations(label_path, width, height)\n",
    "\n",
    "           \n",
    "            annotated_image = annotate_image(image.copy(), annotations)\n",
    "\n",
    "    \n",
    "            annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
    "            images.append(annotated_image)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erreur lors du traitement de l'image {img_path} : {e}\")\n",
    "\n",
    "    return images\n",
    "\n",
    "def display_images_in_grid(images, grid_size=(GRID_SIZE, GRID_SIZE), fig_size=(15, 15)):\n",
    "    fig, axes = plt.subplots(grid_size[0], grid_size[1], figsize=fig_size)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(len(axes)):\n",
    "        if i < len(images):\n",
    "            axes[i].imshow(images[i])\n",
    "            axes[i].axis('off')\n",
    "        else:\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"🔄 Chargement des images avec annotations...\")\n",
    "annotated_images = load_and_annotate_images()\n",
    "\n",
    "if annotated_images:\n",
    "    print(f\"✅ {len(annotated_images)} images chargées et annotées.\")\n",
    "    display_images_in_grid(annotated_images)\n",
    "else:\n",
    "    print(\"⚠️ Aucune image chargée.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.86  Python-3.12.3 torch-2.5.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "Setup complete  (8 CPUs, 15.8 GB RAM, 270.5/284.9 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import settings\n",
    "\n",
    "# Update a setting\n",
    "settings.update({\n",
    "    'mlflow': False,\n",
    "    'clearml': False,\n",
    "    'comet': False,\n",
    "    'dvc': False,\n",
    "    'hub': False,\n",
    "    'neptune': False,\n",
    "    'raytune': False,\n",
    "    'tensorboard': False,\n",
    "    'wandb': True\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning Modele Yolo :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model_path = os.path.join(\n",
    "    \"runs\", \"detect\", \"YOLOv8_finetune_signature\", \"weights\", \"best.pt\"\n",
    ")\n",
    "save_as = \"finetuned_yolov8_signature_best.pt\"\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    shutil.copy(best_model_path, save_as)\n",
    "    print(f\"✅ Meilleur modèle sauvegardé sous : {save_as}\")\n",
    "else:\n",
    "    print(f\"⚠️ Aucun fichier best.pt trouvé dans : {best_model_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.91 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.88  Python-3.12.3 torch-2.5.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=Assurances/YOLO_Trained/yolov8sFinal.pt, data=C:/Users/ilyes/intelligIA/datasets/signature/signature.yaml, epochs=50, time=None, patience=8, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=Signature-Detection-FineTune, name=YOLOv8_finetune_signature15, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=True, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=0, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=5e-05, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.1, degrees=10, translate=0.1, scale=0.5, shear=4.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=Signature-Detection-FineTune\\YOLOv8_finetune_signature15\n",
      "Overriding class names with single class.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,135,987 parameters, 11,135,971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: Scanning C:\\Users\\ilyes\\intelligIA\\datasets\\signature\\train\\labels.cache... 143 images, 0 backgrounds, 0 corrupt: 100%|██████████| 143/143 [00:00<?, ?it/s]Scanning C:\\Users\\ilyes\\intelligIA\\datasets\\signature\\train\\labels.cache... 143 images, 0 backgrounds, 0 corrupt: 100%|██████████| 143/143 [00:00<?, ?it/s]\n",
      "val: Scanning C:\\Users\\ilyes\\intelligIA\\datasets\\signature\\valid\\labels.cache... 35 images, 0 backgrounds, 0 corrupt: 100%|██████████| 35/35 [00:00<?, ?it/s]Scanning C:\\Users\\ilyes\\intelligIA\\datasets\\signature\\valid\\labels.cache... 35 images, 0 backgrounds, 0 corrupt: 100%|██████████| 35/35 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to Signature-Detection-FineTune\\YOLOv8_finetune_signature15\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=5e-05' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mSignature-Detection-FineTune\\YOLOv8_finetune_signature15\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G      1.539       1.11      1.822         25        640: 100%|██████████| 18/18 [02:11<00:00,  7.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.832      0.943      0.936      0.662\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50         0G      1.217     0.7945      1.551         16        640: 100%|██████████| 18/18 [01:50<00:00,  6.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.899      0.943      0.959      0.774\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50         0G      1.238     0.8526      1.564         14        640: 100%|██████████| 18/18 [01:45<00:00,  5.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.969      0.943       0.99      0.728\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50         0G      1.213     0.8197      1.591         14        640: 100%|██████████| 18/18 [01:38<00:00,  5.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.996      0.943      0.991      0.705\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50         0G      1.243     0.8161       1.56         20        640: 100%|██████████| 18/18 [01:37<00:00,  5.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.941          1      0.986      0.777\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50         0G      1.089     0.7892      1.447         14        640: 100%|██████████| 18/18 [01:37<00:00,  5.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35          1      0.994      0.995      0.681\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50         0G      1.083     0.7191       1.47         14        640: 100%|██████████| 18/18 [01:40<00:00,  5.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.993          1      0.995       0.68\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50         0G       1.11     0.8192      1.446         16        640: 100%|██████████| 18/18 [01:38<00:00,  5.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.917      0.914      0.977      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50         0G      1.063     0.8109        1.4         17        640: 100%|██████████| 18/18 [01:37<00:00,  5.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.931      0.829      0.939      0.622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50         0G      1.162     0.8268      1.491         13        640: 100%|██████████| 18/18 [01:38<00:00,  5.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35       0.98          1      0.995      0.717\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50         0G      1.059     0.6416      1.415         16        640: 100%|██████████| 18/18 [01:37<00:00,  5.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35          1      0.938      0.993      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50         0G      0.986     0.6351      1.354         12        640: 100%|██████████| 18/18 [01:36<00:00,  5.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35          1      0.968      0.994      0.749\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50         0G     0.9009     0.5886      1.261         16        640: 100%|██████████| 18/18 [01:36<00:00,  5.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.997          1      0.995      0.787\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50         0G     0.9575     0.6003       1.32         17        640: 100%|██████████| 18/18 [01:53<00:00,  6.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.996          1      0.995      0.827\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50         0G     0.9897     0.6346      1.319         17        640: 100%|██████████| 18/18 [01:47<00:00,  5.98s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.995          1      0.995      0.756\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50         0G     0.9924     0.6104      1.374         15        640: 100%|██████████| 18/18 [01:44<00:00,  5.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.996          1      0.995      0.726\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50         0G      1.013     0.6256      1.316         22        640: 100%|██████████| 18/18 [01:47<00:00,  5.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.967          1      0.994      0.619\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50         0G     0.9557     0.6273      1.344          8        640: 100%|██████████| 18/18 [01:46<00:00,  5.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.959      0.971      0.991      0.744\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50         0G     0.9022     0.5726      1.302         15        640: 100%|██████████| 18/18 [01:46<00:00,  5.91s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.944          1      0.993      0.728\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50         0G     0.8397     0.5563      1.229         15        640: 100%|██████████| 18/18 [01:46<00:00,  5.90s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.966      0.971      0.987      0.762\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50         0G     0.8957     0.5596      1.296         18        640: 100%|██████████| 18/18 [01:48<00:00,  6.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.997          1      0.995      0.691\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50         0G     0.9545     0.6186      1.332         13        640: 100%|██████████| 18/18 [01:46<00:00,  5.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.974          1      0.995      0.718\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 8 epochs. Best results observed at epoch 14, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=8) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "22 epochs completed in 0.677 hours.\n",
      "Optimizer stripped from Signature-Detection-FineTune\\YOLOv8_finetune_signature15\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from Signature-Detection-FineTune\\YOLOv8_finetune_signature15\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating Signature-Detection-FineTune\\YOLOv8_finetune_signature15\\weights\\best.pt...\n",
      "Ultralytics 8.3.88  Python-3.12.3 torch-2.5.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         35         35      0.996          1      0.995      0.827\n",
      "Speed: 2.5ms preprocess, 120.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mSignature-Detection-FineTune\\YOLOv8_finetune_signature15\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>▁▃▄▆▇█████▇▇▇▇▇▆▆▆▆▅▅▅</td></tr><tr><td>lr/pg1</td><td>▁▃▄▆▇█████▇▇▇▇▇▆▆▆▆▅▅▅</td></tr><tr><td>lr/pg2</td><td>▁▃▄▆▇█████▇▇▇▇▇▆▆▆▆▅▅▅</td></tr><tr><td>metrics/mAP50(B)</td><td>▁▄▇▇▇██▆▁██████████▇██</td></tr><tr><td>metrics/mAP50-95(B)</td><td>▃▆▅▄▆▄▄▁▂▅▄▆▇█▆▅▂▅▅▆▄█</td></tr><tr><td>metrics/precision(B)</td><td>▁▄▇█▆██▅▅▇██████▇▆▆▇██</td></tr><tr><td>metrics/recall(B)</td><td>▆▆▆▆███▅▁█▅▇█████▇█▇██</td></tr><tr><td>model/GFLOPs</td><td>▁</td></tr><tr><td>model/parameters</td><td>▁</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>▁</td></tr><tr><td>train/box_loss</td><td>█▅▅▅▅▃▃▄▃▄▃▂▂▂▃▃▃▂▂▁▂▂</td></tr><tr><td>train/cls_loss</td><td>█▄▅▄▄▄▃▄▄▄▂▂▁▂▂▂▂▂▁▁▁▂</td></tr><tr><td>train/dfl_loss</td><td>█▅▅▅▅▄▄▄▃▄▃▂▁▂▂▃▂▂▂▁▂▂</td></tr><tr><td>val/box_loss</td><td>▆▃▄▇▁▇▅▄█▄▇▄▂▁▃▄▄▃▄▃▄▂</td></tr><tr><td>val/cls_loss</td><td>▂▃▂▂▃▂▂██▂▃▂▂▁▂▂▂▂▂▂▁▂</td></tr><tr><td>val/dfl_loss</td><td>▄▁▃▆▁▆▄▇█▃▅▃▂▁▂▃▄▂▃▁▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.00126</td></tr><tr><td>lr/pg1</td><td>0.00126</td></tr><tr><td>lr/pg2</td><td>0.00126</td></tr><tr><td>metrics/mAP50(B)</td><td>0.995</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.82719</td></tr><tr><td>metrics/precision(B)</td><td>0.99561</td></tr><tr><td>metrics/recall(B)</td><td>1</td></tr><tr><td>model/GFLOPs</td><td>28.647</td></tr><tr><td>model/parameters</td><td>11135987</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>137.956</td></tr><tr><td>train/box_loss</td><td>0.95451</td></tr><tr><td>train/cls_loss</td><td>0.61864</td></tr><tr><td>train/dfl_loss</td><td>1.3324</td></tr><tr><td>val/box_loss</td><td>0.92959</td></tr><tr><td>val/cls_loss</td><td>0.63845</td></tr><tr><td>val/dfl_loss</td><td>1.11018</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">YOLOv8_finetune_signature14</strong> at: <a href='https://wandb.ai/ilyessais2000-intellig-ia/Signature-Detection-FineTune/runs/tmfs0gxi' target=\"_blank\">https://wandb.ai/ilyessais2000-intellig-ia/Signature-Detection-FineTune/runs/tmfs0gxi</a><br> View project at: <a href='https://wandb.ai/ilyessais2000-intellig-ia/Signature-Detection-FineTune' target=\"_blank\">https://wandb.ai/ilyessais2000-intellig-ia/Signature-Detection-FineTune</a><br>Synced 5 W&B file(s), 21 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250317_021419-tmfs0gxi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.88  Python-3.12.3 torch-2.5.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "Une erreur est survenue : val: Error loading data from C:\\Users\\ilyes\\intelligIA\\datasets\\signature\\test\\images\n",
      "See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "import mlflow\n",
    "from ultralytics import YOLO\n",
    "\n",
    "MODEL_CHECKPOINT = \"Assurances/YOLO_Trained/yolov8sFinal.pt\"\n",
    "DATA_YAML = \"C:/Users/ilyes/intelligIA/datasets/signature/signature.yaml\"\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 8\n",
    "BASE_LR = 5e-5\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"file:///\" + os.path.abspath(\"mlruns\")\n",
    "EXPERIMENT_NAME = \"YOLO_Signature_FineTune\"\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "try:\n",
    "    with mlflow.start_run() as run:\n",
    "        mlflow.log_param(\"model_checkpoint\", MODEL_CHECKPOINT)\n",
    "        mlflow.log_param(\"data_yaml\", DATA_YAML)\n",
    "        mlflow.log_param(\"epochs\", EPOCHS)\n",
    "        mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "        mlflow.log_param(\"base_lr\", BASE_LR)\n",
    "\n",
    "   \n",
    "        model = YOLO(MODEL_CHECKPOINT)\n",
    "\n",
    "      \n",
    "        results = model.train(\n",
    "            data=DATA_YAML,\n",
    "            epochs=EPOCHS,\n",
    "            batch=BATCH_SIZE,\n",
    "            lr0=BASE_LR,\n",
    "            imgsz=640,\n",
    "            single_cls=True,\n",
    "            cos_lr=True,\n",
    "            patience=8,\n",
    "            freeze=0,\n",
    "            degrees=10,\n",
    "            shear=4.0,\n",
    "            hsv_v=0.1,\n",
    "            flipud=0.0,\n",
    "            fliplr=0.5,\n",
    "            scale=0.5,\n",
    "            project=\"Signature-Detection-FineTune\",\n",
    "            name=\"YOLOv8_finetune_signature\",\n",
    "            verbose=False,\n",
    "            save=True         \n",
    "        )\n",
    "\n",
    "        results_test = model.val(\n",
    "            data=DATA_YAML,\n",
    "            split=\"test\",\n",
    "            imgsz=640,\n",
    "            conf=0.25\n",
    "        )\n",
    "        print(\"[INFO] Résultats test :\", results_test)\n",
    "\n",
    "        try:\n",
    "            mAP50 = results_test.box.maps[0]\n",
    "            mlflow.log_metric(\"mAP50_test\", mAP50)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] Impossible de logguer les métriques YOLO : {e}\")\n",
    "\n",
    "  \n",
    "        export_name = \"signature_finetuned\"\n",
    "        export_path = model.export(\n",
    "            format=\"torchscript\",\n",
    "            imgsz=640,\n",
    "            name=export_name,\n",
    "            dynamic=False,     \n",
    "            simplify=False     \n",
    "        )\n",
    "\n",
    "\n",
    "        print(f\"[INFO] Modèle exporté en TorchScript : {export_path}\")\n",
    "\n",
    "      \n",
    "        if os.path.exists(export_path):\n",
    "            mlflow.log_artifact(export_path, artifact_path=\"model\")\n",
    "            print(f\"[INFO] Modèle .pt loggué dans MLflow : {export_path}\")\n",
    "        else:\n",
    "            print(\"[WARNING] Export .pt introuvable.\")\n",
    "\n",
    "        print(\"[INFO] Fin du run MLflow :\", run.info.run_id)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Une erreur est survenue :\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.17.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnx\n",
    "onnx.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.88  Python-3.12.3 torch-2.5.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\Y'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\Y'\n",
      "C:\\Users\\ilyes\\AppData\\Local\\Temp\\ipykernel_31364\\4003746343.py:4: SyntaxWarning: invalid escape sequence '\\Y'\n",
      "  MODEL_PT = \"Signature-Detection-FineTune\\YOLOv8_finetune_signature7\\weights\\llest.pt\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'Signature-Detection-FineTune\\YOLOv8_finetune_signature7\\weights\\llest.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (21.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.48...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.4s, saved as 'Signature-Detection-FineTune\\YOLOv8_finetune_signature7\\weights\\llest.onnx' (42.7 MB)\n",
      "\n",
      "Export complete (3.0s)\n",
      "Results saved to \u001b[1mC:\\Users\\ilyes\\intelligIA\\Signature-Detection-FineTune\\YOLOv8_finetune_signature7\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=Signature-Detection-FineTune\\YOLOv8_finetune_signature7\\weights\\llest.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=Signature-Detection-FineTune\\YOLOv8_finetune_signature7\\weights\\llest.onnx imgsz=640 data=C:/Users/ilyes/intelligIA/datasets/signature/signature.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Modèle ONNX généré : Signature-Detection-FineTune\\YOLOv8_finetune_signature7\\weights\\llest.onnx\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "MODEL_PT = \"Signature-Detection-FineTune\\YOLOv8_finetune_signature7\\weights\\llest.pt\" \n",
    "\n",
    "\n",
    "model = YOLO(MODEL_PT)\n",
    "\n",
    "onnx_path = model.export(\n",
    "    format=\"onnx\",\n",
    "    opset=12,\n",
    "    imgsz=640,\n",
    "    dynamic=False,\n",
    "    name=\"signature_finetuned_onnx\"\n",
    ")\n",
    "\n",
    "print(f\"Modèle ONNX généré : {onnx_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
